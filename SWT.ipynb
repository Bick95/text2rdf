{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# text2rdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General purpose\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# PyTorch \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "\n",
    "# Bert\n",
    "from transformers import BertTokenizer, BertModel, BertConfig\n",
    "#Bleu score\n",
    "from nltk.translate.bleu_score import corpus_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
   ],
   "source": [
    "# CUDA related\n",
    "device = torch.device('cuda')\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Data-sub-set (given restricted nr of triples per sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many triples to train and test system on (min: 1, max: 7)\n",
    "MIN_NUM_TRIPLES = 2\n",
    "MAX_NUM_TRIPLES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths where to retrieve data from\n",
    "DS_BASE_PATH = './WebNLG/'\n",
    "\n",
    "TRAIN_PATH = DS_BASE_PATH + 'train/'\n",
    "TEST_PATH = DS_BASE_PATH + 'dev/'\n",
    "\n",
    "TRAIN_DIRS = [ TRAIN_PATH + str(i) + 'triples/' for i in range(MIN_NUM_TRIPLES, MAX_NUM_TRIPLES+1) ]\n",
    "TEST_DIRS  = [ TEST_PATH  + str(i) + 'triples/' for i in range(MIN_NUM_TRIPLES, MAX_NUM_TRIPLES+1) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dirs: ['./WebNLG/train/2triples/']\n",
      "Test  dirs: ['./WebNLG/dev/2triples/']\n"
     ]
    }
   ],
   "source": [
    "# Print selected directories\n",
    "print('Train dirs:', TRAIN_DIRS)\n",
    "print('Test  dirs:', TEST_DIRS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Settings (do not touch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "originaltripleset_index = 0  # Index of 'originaltripleset' attribute in XML entry\n",
    "modifiedtripleset_index = 1  # Index of 'modifiedtripleset' attribute in XML entry\n",
    "first_lexical_index = 2      # Index as of which verbalizations of RDF triples start in entry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2472]\n"
     ]
    }
   ],
   "source": [
    "# Usage of train: train[target_nr_triples][element_id]['target_attribute']\n",
    "train = [[] for i in range(MIN_NUM_TRIPLES, MAX_NUM_TRIPLES+1)]\n",
    "\n",
    "# Documents how many entries there are per number of triples\n",
    "train_stats = [0 for i in range(MIN_NUM_TRIPLES, MAX_NUM_TRIPLES+1)]\n",
    "\n",
    "# Iterate through all files per number of triples and per category and load data\n",
    "for i, d in enumerate(TRAIN_DIRS):\n",
    "    nr_triples = list(range(MIN_NUM_TRIPLES, MAX_NUM_TRIPLES+1))[i]\n",
    "    \n",
    "    for filename in glob.iglob(d+'/**', recursive=False):\n",
    "        if os.path.isfile(filename): # Filter dirs\n",
    "            #print('File:', filename)\n",
    "            \n",
    "            tree = ET.parse(filename)\n",
    "            root = tree.getroot()\n",
    "            \n",
    "            entries = root[0]\n",
    "            train_stats[nr_triples-MIN_NUM_TRIPLES] += len(entries)\n",
    "            \n",
    "            for entry in entries:\n",
    "                #print('Original triple set: ', entry[originaltripleset_index])\n",
    "                #print('Modified triple set: ', entry[modifiedtripleset_index])\n",
    "                \n",
    "                modified_triple_set = entry[modifiedtripleset_index]\n",
    "                unified_triple_set = []\n",
    "                \n",
    "                for triple in modified_triple_set:\n",
    "                    # Make a list containing a conjunction of all individual triples\n",
    "                    triple_list = [x.strip() for x in triple.text.split('|')]\n",
    "                    unified_triple_set += triple_list\n",
    "                    \n",
    "                verbalizations = entry[first_lexical_index:]\n",
    "\n",
    "                for verbalization in verbalizations:\n",
    "                    if verbalization.text.strip() == '':\n",
    "                        continue\n",
    "                    #print('Text:', verbalization, verbalization.tag, verbalization.attrib, verbalization.text)\n",
    "                    #print('Trip:', triple, triple.tag, triple.attrib, triple.text)\n",
    "\n",
    "                    train[i].append({ 'category': entry.attrib['category'],\n",
    "                                      'id': entry.attrib['eid'],\n",
    "                                      'triple_cnt': nr_triples,\n",
    "                                      'text': verbalization.text,\n",
    "                                      'triple': unified_triple_set,\n",
    "                                    })\n",
    "                        \n",
    "# print(train)\n",
    "print(train_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[313]\n"
     ]
    }
   ],
   "source": [
    "# Usage of test: test[target_nr_triples][element_id]['target_attribute']\n",
    "test = [[] for i in range(MIN_NUM_TRIPLES, MAX_NUM_TRIPLES+1)]\n",
    "\n",
    "# Documents how many entries there are per number of triples\n",
    "test_stats = [0 for i in range(MIN_NUM_TRIPLES, MAX_NUM_TRIPLES+1)]\n",
    "\n",
    "# Iterate through all files per number of triples and per category and load data\n",
    "for i, d in enumerate(TEST_DIRS):\n",
    "    nr_triples = list(range(MIN_NUM_TRIPLES, MAX_NUM_TRIPLES+1))[i]\n",
    "    \n",
    "    for filename in glob.iglob(d+'/**', recursive=False):\n",
    "        if os.path.isfile(filename): # Filter dirs\n",
    "            #print('File:', filename)\n",
    "            \n",
    "            tree = ET.parse(filename)\n",
    "            root = tree.getroot()\n",
    "            \n",
    "            entries = root[0]\n",
    "            test_stats[nr_triples-MIN_NUM_TRIPLES] += len(entries)\n",
    "            \n",
    "            for entry in entries:\n",
    "                #print('Original triple set: ', entry[originaltripleset_index])\n",
    "                #print('Modified triple set: ', entry[modifiedtripleset_index])\n",
    "                \n",
    "                modified_triple_set = entry[modifiedtripleset_index]\n",
    "                unified_triple_set = []\n",
    "                \n",
    "                for triple in modified_triple_set:\n",
    "                    # Make a list containing a conjunction of all individual triples\n",
    "                    triple_list = [x.strip() for x in triple.text.split('|')]\n",
    "                    unified_triple_set += triple_list\n",
    "                    \n",
    "                verbalizations = entry[first_lexical_index:]\n",
    "\n",
    "                for verbalization in verbalizations:\n",
    "                    if verbalization.text.strip() == '':\n",
    "                        continue\n",
    "                    #print('Text:', verbalization, verbalization.tag, verbalization.attrib, verbalization.text)\n",
    "                    #print('Trip:', triple, triple.tag, triple.attrib, triple.text)\n",
    "\n",
    "                    test[i].append({ 'category': entry.attrib['category'],\n",
    "                                      'id': entry.attrib['eid'],\n",
    "                                      'triple_cnt': nr_triples,\n",
    "                                      'text': verbalization.text,\n",
    "                                      'triple': unified_triple_set,\n",
    "                                    })\n",
    "                        \n",
    "# print(test)\n",
    "print(test_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spilt Train Data into Train and Dev (for intermindiate validation throughout training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage of train data reserved for validation throughout training\n",
    "dev_percentage = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples per nr of triples: [370]\n",
      "[370]\n"
     ]
    }
   ],
   "source": [
    "# Init dev dataset\n",
    "dev = [[] for i in range(MIN_NUM_TRIPLES, MAX_NUM_TRIPLES+1)]\n",
    "\n",
    "# Sample number of dev instances per number of triples\n",
    "dev_stats = [int(dev_percentage * train_stats[i]) for i in range(0, MAX_NUM_TRIPLES+1-MIN_NUM_TRIPLES)]\n",
    "\n",
    "print('Samples per nr of triples:', dev_stats)\n",
    "\n",
    "# Sample indices to be reserved for dev dataset for each nr of triples\n",
    "dev_indices = [random.sample(range(0, len(train[i])), dev_stats[i]) for i in range(0, MAX_NUM_TRIPLES+1-MIN_NUM_TRIPLES)]\n",
    "for i in range(len(dev_indices)):\n",
    "    dev_indices[i].sort(reverse=True)\n",
    "\n",
    "# Copy selected dev-entries into dev & delete all duplicates/related entries from train dataset\n",
    "for nr_triples in range(0, MAX_NUM_TRIPLES+1-MIN_NUM_TRIPLES):\n",
    "    \n",
    "    # Iterate through all indices reserved for validation set (per nr of triples)\n",
    "    for index in dev_indices[nr_triples]:\n",
    "        \n",
    "        # Select index'th train entry (to become dev/validation data)\n",
    "        selected_entry = train[nr_triples][index]\n",
    "        \n",
    "        # Extract indentifying attributes\n",
    "        entrys_category = selected_entry['category']\n",
    "        entrys_idx = selected_entry['id']\n",
    "        \n",
    "        # Put selected entry into dev set\n",
    "        dev[nr_triples].append(selected_entry)\n",
    "        \n",
    "        # Find all entries of matching index & category and remove them from train data\n",
    "        for entry in train[nr_triples]:\n",
    "            if entry['id'] == entrys_idx and entry['category'] == entrys_category:\n",
    "                train[nr_triples].remove(entry)\n",
    "                \n",
    "# print(dev)\n",
    "print(dev_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimal number of triples: 2\n",
      "Maximal number of triples: 2\n",
      "\n",
      "Training: \n",
      "Given 2 triples per sentence: \n",
      "Number of combinations of triples and verbalizations: 6257\n",
      "\n",
      "Dev: \n",
      "Given 2 triples per sentence: \n",
      "Number of combinations of triples and verbalizations: 370\n",
      "\n",
      "Testing: \n",
      "Given 2 triples per sentence: \n",
      "Number of combinations of triples and verbalizations: 875\n"
     ]
    }
   ],
   "source": [
    "print('Minimal number of triples:', MIN_NUM_TRIPLES)\n",
    "print('Maximal number of triples:', MAX_NUM_TRIPLES)\n",
    "\n",
    "print()\n",
    "\n",
    "print('Training: ')\n",
    "for nr_triples in range(MIN_NUM_TRIPLES, MAX_NUM_TRIPLES+1):\n",
    "    print('Given %i triples per sentence: ' % nr_triples)\n",
    "    print('Number of combinations of triples and verbalizations:', len(train[nr_triples-MIN_NUM_TRIPLES]))\n",
    "\n",
    "print()\n",
    "\n",
    "print('Dev: ')\n",
    "for nr_triples in range(MIN_NUM_TRIPLES, MAX_NUM_TRIPLES+1):\n",
    "    print('Given %i triples per sentence: ' % nr_triples)\n",
    "    print('Number of combinations of triples and verbalizations:', len(dev[nr_triples-MIN_NUM_TRIPLES]))\n",
    "\n",
    "print()\n",
    "\n",
    "print('Testing: ')\n",
    "for nr_triples in range(MIN_NUM_TRIPLES, MAX_NUM_TRIPLES+1):\n",
    "    print('Given %i triples per sentence: ' % nr_triples)\n",
    "    print('Number of combinations of triples and verbalizations:', len(test[nr_triples-MIN_NUM_TRIPLES]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Machine Translation (NMT) Model Definition \n",
    "\n",
    "## TODO: needs updating\n",
    "\n",
    "## Idea:\n",
    "1. Encoder: \n",
    "1.1 Input==Word Embedding; \n",
    "1.2 Output==Context Vector (that is: Encoding of sentence; contained in hidden state after having observed last embedding)\n",
    "\n",
    "2. Decoder:\n",
    "2.1 Input==Context Vector\n",
    "2.2 Output==Probability distribution over output vocab\n",
    "\n",
    "3. Seq2Seq model: Combining the two"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = BertModel.from_pretrained('bert-base-uncased', return_dict=True).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Soft Attention Model\n",
    "This model implements the Soft Attention model presented in http://proceedings.mlr.press/v37/xuc15.pdf. \n",
    "1. Attention energies (i.e. energy per annotation vector) get computed: $e_{ti}=f_{att}(a_i,h_{t−1})$. Note that this formula implies that the Decoder's previous hidden state $h_{t-1}$ needs to be appended to each individual annotation vector $a_i$ before feeding their concatenation through a fully-connected layer $f_{att}$. \n",
    "2. Attention weights $\\alpha$ get computed from the aforementioned energies: $\\alpha_t = softmax(e_t)$, where $\\alpha_{ti} = \\frac{exp(e_{ti})}{\\sum^L_{k=1} exp(e_{tk})}$.\n",
    "\n",
    "Note: $t$ stands for time, while $i$ identifies the particular annotation vector currently under consideration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftAttention(nn.Module):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 annotation_size,  # Tuple: (num_annotations, num_features_per_annotation)\n",
    "                 hidden_len        # Number of nodes in Decoder's hidden state weight matrix\n",
    "                ):\n",
    "        \n",
    "        super(SoftAttention, self).__init__()\n",
    "        #print('SA INIT')\n",
    "        # Variables\n",
    "        self.num_annotations = annotation_size[0]\n",
    "        self.annotation_features = annotation_size[1]\n",
    "        self.hidden_size = hidden_len\n",
    "        \n",
    "        # Layers\n",
    "        self.attn = nn.Linear(self.annotation_features + self.hidden_size, 1, bias=True)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        #print('an size:', annotation_size) # 8x96\n",
    "        #print('an features (96?):', self.annotation_features) # 96\n",
    "        #print('hid size:', hidden_len)     # 96\n",
    "        \n",
    "    def forward(self, annotations, prev_hidden):\n",
    "        \n",
    "        # Repeat prev_hidded X times to append it to each of the annotation vectors (per batch element)\n",
    "        repeated_hidden = torch.cat(\n",
    "            [\n",
    "                torch.repeat_interleave(hid, repeats=self.num_annotations, dim=0).unsqueeze(0)\n",
    "                for hid in prev_hidden.split(1)\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        # Append previous hidden state to all annotation vectors (for each individual batch element)\n",
    "        # Input to attention weight calculation\n",
    "        #print('SA:', annotations.size(), repeated_hidden.size())\n",
    "        input = torch.cat((annotations, repeated_hidden), dim=2)\n",
    "        #print('Input size:', input.size())\n",
    "        #print(self.attn)\n",
    "        \n",
    "        # Compute the relative attention scores per feaure (e_{ti}=f_{att}(a_i,h_{t−1}) from paper)\n",
    "        energies = self.attn(input)\n",
    "        \n",
    "        #print('energies...')\n",
    "        \n",
    "        # Compute final attention weights (i.e. alpha)\n",
    "        attn_weights = self.softmax(energies)\n",
    "        #print('attn_weights:', attn_weights.size())\n",
    "        return attn_weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder itself (employing Soft Attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 annotation_size,      # Size of annotation vectors produced by Encoder\n",
    "                 out_vocab_size,       # How many words there are in the RDF-output language\n",
    "                 embedding_dim,        # Length of a word embedding\n",
    "                 hidden_dim,           # Nr hidden nodes\n",
    "                 output_dim,           # Vocab size\n",
    "                 bidirectional=False,  # Whether to have bidirectional GRU\n",
    "                 n_layers=1,           # Nr layers in GRU\n",
    "                 drop_prob=0.2         # Percent of node-dropouts\n",
    "                ):\n",
    "        \n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.n_directions = 1 if not bidirectional else 2  # TODO: make use of it...\n",
    "        \n",
    "        self.attn = SoftAttention(annotation_size=annotation_size, hidden_len=hidden_dim)\n",
    "        self.gru = nn.GRU(annotation_size[1]+embedding_dim, hidden_dim, n_layers, batch_first=True, dropout=drop_prob)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "        \n",
    "    def forward(self, \n",
    "                annotations,  # Static annotation vectors (for each batch element)\n",
    "                embeddings,   # Word embeddings of most recently generated word (per batch element)\n",
    "                h_old         # Previous hidden state per batch element\n",
    "               ):\n",
    "        #print('Decoder forward:')\n",
    "        #print('embeddings:\\t', embeddings.size())\n",
    "        #print('h_old:\\t\\t', h_old.size())\n",
    "        \n",
    "        annotation_weights = self.attn(annotations, h_old.squeeze())#.unsqueeze(2)\n",
    "        #print('annotations:', annotations.size())\n",
    "        #print('annotation_weights:', annotation_weights.size())\n",
    "        weighted_annotations = annotations * annotation_weights\n",
    "        #print('weighted_annotations:', weighted_annotations.size())\n",
    "        context_vectors = torch.sum(weighted_annotations, dim=1)\n",
    "        #print('context_vectors:', context_vectors.size())\n",
    "        \n",
    "        x = torch.cat((context_vectors, embeddings), dim=1)\n",
    "        #print('x:', x.size())\n",
    "        x = x.unsqueeze(1) # Add une dimension for 'sequence'\n",
    "        \n",
    "        #print('Decoder x:', x.size(), 'h_old:', h_old.size())\n",
    "        #print(self.gru)\n",
    "        out, h = self.gru(x, h_old)\n",
    "        out = out.squeeze()\n",
    "        out = self.softmax(self.fc(self.relu(out)))\n",
    "        #print('h:', h.size())\n",
    "        return out, h\n",
    "    \n",
    "    \n",
    "    def init_hidden(self, annotation_vectors):\n",
    "        # Mean of annotation vector per batch element\n",
    "        # Assumes that number of hidden nodes == number annotation features\n",
    "        hidden = torch.mean(annotation_vectors, dim=1)#.to(device)\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder for seq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use it only if required otherwise can be removed.\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 input_dim,\n",
    "                 embedding_dim,        # Length of a word embedding\n",
    "                 hidden_dim,           # Nr hidden nodes\n",
    "                 n_layers = 1,         # Nr layers in GRU\n",
    "                 dropout =0.2\n",
    "                ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        \n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, src):        \n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        #embedded = [src len, batch size, emb dim] \n",
    "        \n",
    "        outputs, (hidden, cell) = self.rnn(embedded)\n",
    "        \n",
    "        #outputs =\n",
    "        #hidden =\n",
    "        #cell =\n",
    "        \n",
    "        #outputs are always from the top hidden layer\n",
    "        \n",
    "        return hidden, cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x, \n",
    "            word_embeddings,        # Decoder's word embeddings\n",
    "            word2idx,               # \n",
    "            idx2word,               # \n",
    "            encoder,                # \n",
    "            decoder,                # \n",
    "            tokenizer,              # \n",
    "            loss_fn,                # \n",
    "            max_len=7,              # \n",
    "            batch_size=32,          # \n",
    "            compute_grads=False,    # \n",
    "            targets=None,           # \n",
    "            return_textual=False    # Whether to return predictions in index-form (default) or as textual strings\n",
    "           ):\n",
    "    \n",
    "    print('In predict:')\n",
    "    \n",
    "    accumulated_loss = 0.\n",
    "    \n",
    "    # Init documentation of predictions\n",
    "    predicted_indices = torch.zeros([batch_size, max_len]).to(device) # Numeric\n",
    "    if return_textual:\n",
    "        predicted_words = ['']*batch_size\n",
    "    \n",
    "    # Tokenize sampled minibatch sentences\n",
    "    inputs = tokenizer(x, \n",
    "                       return_tensors=\"pt\",     # Return tensors in pt=PyTorch format\n",
    "                       padding=True,            # Pad all sentences in mini-batch to have the same length\n",
    "                       add_special_tokens=True).to(device) # Add \"Start of sequence\", \"End of sequence\", ... tokens. \n",
    "    \n",
    "    #print('Tokenized Inputs:', inputs)\n",
    "    \n",
    "    # Encode sentences: Pass tokenization output-dict-contents to model\n",
    "    outputs = encoder(**inputs)\n",
    "    #print('Got outputs:', outputs)\n",
    "\n",
    "    # Retrieve hidden state to be passed into Decoder as annotation vectors\n",
    "    # Reshape to get a set of 8 feature vectors from last hidden state\n",
    "    annotations = outputs.last_hidden_state[:, -1, :].reshape(batch_size,8,-1).to(device)\n",
    "    #print('Annotations size after cropping & reshape:', annotations.size())\n",
    "\n",
    "    # Init Decoder's hidden state\n",
    "    hidden = decoder.init_hidden(annotations).unsqueeze(0).to(device)\n",
    "    #print('Initial hidden size:', hidden.size(), 'given annotations:', annotations.size())\n",
    "    \n",
    "    # Construct initial embeddings (start tokens)\n",
    "    embeddings = word_embeddings(torch.zeros([batch_size], dtype=int).to(device)).to(device)\n",
    "    \n",
    "    for t in range(max_len):\n",
    "        #print('START OF ITERATION', t)\n",
    "        # Get decodings (aka prob distrib. over output vocab per batch element) for time step t\n",
    "        prob_dist, hidden = decoder(annotations, # Static vector containing annotations per batch element \n",
    "                                    embeddings,  # Word embedding predicted last iteration (per batch element)\n",
    "                                    hidden       # Decoder's hidden state of last iteratipn per batch element\n",
    "                                    )\n",
    "\n",
    "        # Get predicted word index from predicted probability distribution (per batch element)\n",
    "        word_index = torch.max(prob_dist, dim=1).indices\n",
    "        #print('Predicted word indices batch:', word_index)\n",
    "        \n",
    "        # Get corresponding word embedding (by index; per batch element)\n",
    "        embedding = word_embeddings(word_index.to(device))\n",
    "        \n",
    "        # TODO: optional teacher forcing?\n",
    "\n",
    "        # Record predicted words\n",
    "        predicted_indices[:, t] = word_index\n",
    "        #print('Predicted indices:', predicted_indices)\n",
    "        \n",
    "        # Record textual words if required\n",
    "        if return_textual:\n",
    "            \n",
    "            # Get predicted word (per batch element)\n",
    "            predicted_word = [idx2word[batch_element.item()] for batch_element in word_index]\n",
    "        \n",
    "            for e in range(batch_size):\n",
    "                predicted_words[e] += (predicted_word[e] + ' ')\n",
    "\n",
    "        if compute_grads:\n",
    "            \n",
    "            #print('prob_dist:', prob_dist.size())\n",
    "            #print('targets:', targets[:, t].size(), targets[:, t])\n",
    "            \n",
    "            # Compute (averaged over all batch elements given current time step t)\n",
    "            loss = loss_fn(prob_dist, targets[:, t]).to(device)\n",
    "\n",
    "            # Compute & back-propagate gradients\n",
    "            loss.backward(retain_graph=True)\n",
    "            \n",
    "            # Document loss\n",
    "            accumulated_loss += loss.item()\n",
    "        #print('END OF ITERATION', t)\n",
    "            \n",
    "    ret_object = {\n",
    "        'predicted_indices': predicted_indices,\n",
    "    }\n",
    "    \n",
    "    print('Targets:\\n', targets)\n",
    "    print('Predicted idxs:\\n', predicted_indices)\n",
    "    \n",
    "    if compute_grads:\n",
    "        ret_object['loss'] = accumulated_loss\n",
    "        #print('Accumulated loss:', accumulated_loss)\n",
    "    if return_textual:\n",
    "        ret_object['predicted_words'] = predicted_words\n",
    "        #print(\"Predicted words:\", predicted_words)\n",
    "    #print(\"Returning from predict\")\n",
    "    return ret_object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rdf_vocab_constructor(raw_vocab):\n",
    "    #print(raw_vocab)\n",
    "    vocab_count, word2idx, idx2word = 3, {'START': 0, 'PAD': 1, 'END': 2}, {0: 'START', 1: 'PAD', 2: 'END'}\n",
    "    \n",
    "    for partition in raw_vocab: # Different partitions with respect to nr or triples per sentence\n",
    "        for train_instance in partition:\n",
    "            triple = train_instance['triple']\n",
    "            for token in triple:\n",
    "                if token not in word2idx:\n",
    "                    word2idx[token] = vocab_count\n",
    "                    idx2word[vocab_count] = token\n",
    "                    vocab_count += 1\n",
    "    return vocab_count, word2idx, idx2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(train_data, \n",
    "          val_data,  \n",
    "          epochs, \n",
    "          minibatch_size=32,\n",
    "          embedding_dim=300,\n",
    "          eval_frequency=10, # Every how many epochs to run intermediate evaluation\n",
    "          learning_rate_en=0.00001,\n",
    "          learning_rate_de=0.00001\n",
    "         ):\n",
    "    \n",
    "    # Construct RDF vocab\n",
    "    vocab_count, word2idx, idx2word = rdf_vocab_constructor(train_data)\n",
    "    \n",
    "    # Construct embeddings\n",
    "    rdf_vocab = nn.Embedding(num_embeddings=vocab_count, embedding_dim=embedding_dim, padding_idx=0).to(device)\n",
    "    \n",
    "    # Define model\n",
    "    encoder = bert_model.to(device)\n",
    "    decoder = Decoder(\n",
    "        annotation_size=(8,96),    # Size of annotation vectors produced by Encoder\n",
    "        out_vocab_size=vocab_count, # How many words there are in the RDF-output language\n",
    "        embedding_dim=300,          # Length of a word embedding\n",
    "        hidden_dim=96,             # Nr hidden nodes\n",
    "        output_dim=vocab_count,             # Vocab size\n",
    "    ).to(device)\n",
    "    \n",
    "    # Optimizer\n",
    "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate_en)\n",
    "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate_de)\n",
    "\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # For both train and validation data & for all number of tuples per sentence \n",
    "    # (in [MIN_NUM_TRIPLES, MAX_NUM_TRIPLES]), get the nr of train-/test instances\n",
    "    len_x_train = [len(train_set) for train_set in train]\n",
    "    len_x_val = [len(val_set) for val_set in dev]\n",
    "    \n",
    "    # Development of both train- and validation losses over course of training\n",
    "    train_losses, val_losses = [0.]*epochs, [0.]*epochs\n",
    "    \n",
    "    print('Starting training.')\n",
    "    \n",
    "    # Train\n",
    "    for epoch in range(epochs):\n",
    "        print('Epoch:', epoch)\n",
    "        \n",
    "        train_loss, eval_loss = 0., 0.\n",
    "        \n",
    "        # Reset gradients\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "        \n",
    "        # Perform own train step for each nr of triples per sentence separately\n",
    "        for i, nt in enumerate(range(MIN_NUM_TRIPLES, MAX_NUM_TRIPLES+1)):\n",
    "            print(str(i) + '. Condition:', nt, 'triples per sentence.')\n",
    "            \n",
    "            # Sample minibatch indices\n",
    "            minibatch_idx = random.sample(population=range(len_x_train[i]), k=minibatch_size)\n",
    "            #print('MB indices:', minibatch_idx)\n",
    "            \n",
    "            # Number of tokens to be predicted (per batch element)\n",
    "            num_preds = nt*3+1 # = nr triples * 3 + stop_token \n",
    "            #print('Number of predictions:', num_preds)\n",
    "            \n",
    "            # Construct proper minibatch\n",
    "            inputs = [train_data[i][idx]['text'] for idx in minibatch_idx]\n",
    "            targets = torch.ones([minibatch_size, num_preds], dtype=int).to(device)\n",
    "            \n",
    "            #print('Inputs:', inputs)\n",
    "            #print('Targets:', targets)\n",
    "            \n",
    "            for mb_i, idx in enumerate(minibatch_idx):\n",
    "                #print('Text:', train_data[i][idx]['text'])\n",
    "                #print('Triple:', train_data[i][idx]['triple'])\n",
    "                for t, token in enumerate(train_data[i][idx]['triple']):\n",
    "                    targets[mb_i, t] = word2idx[token]\n",
    "            targets[:, -1] = 2  # 2 = Stop word index\n",
    "            \n",
    "            #print('Processed targets:', targets)\n",
    "            #print('Predicting:')\n",
    "            \n",
    "            # Predict\n",
    "            ret_object = predict(inputs,\n",
    "                                 rdf_vocab,              # Decoder's word embeddings\n",
    "                                 word2idx,               # \n",
    "                                 idx2word,               # \n",
    "                                 encoder,                # \n",
    "                                 decoder,                # \n",
    "                                 tokenizer,              # \n",
    "                                 loss,                   # \n",
    "                                 max_len=num_preds,      # Nr of tokens to be predicted\n",
    "                                 batch_size=32,          # \n",
    "                                 compute_grads=True,     # \n",
    "                                 targets=targets,        # \n",
    "                                 return_textual=True     # Whether to return predictions in index-form (default) or as textual strings\n",
    "                                )\n",
    "            \n",
    "            print('Return object:', ret_object)\n",
    "            print(\"Predicted texts:\", ret_object['predicted_words'])\n",
    "            train_loss += ret_object['loss']\n",
    "            #print(\"Returned loss:\", ret_object['loss'])\n",
    "            \n",
    "        # Apply gradients\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "        #print('Optimizations performed.')\n",
    "        \n",
    "        # Intermediate evaluation\n",
    "        \n",
    "        # Save losses\n",
    "        train_losses[epoch] = train_loss\n",
    "        \n",
    "    return train_losses, val_losses, encoder, decoder, rdf_vocab,  word2idx, idx2word\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daddabarba/.conda/envs/myenv/lib/python3.7/site-packages/torch/nn/modules/rnn.py:61: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training.\n",
      "Epoch: 0\n",
      "0. Condition: 2 triples per sentence.\n",
      "In predict:\n",
      "Targets:\n",
      " tensor([[ 858,  790,  864,  858,  767,  852,    2],\n",
      "        [1805, 1640, 1806, 1806,  220,  570,    2],\n",
      "        [ 972,  406,  981,  972,  767,  974,    2],\n",
      "        [2711, 2593, 2644, 2711, 2652, 2719,    2],\n",
      "        [1591, 1490, 1592, 1591, 1435, 1593,    2],\n",
      "        [ 198,  187,  213,  213,  184,  210,    2],\n",
      "        [ 741,  703,  753,  741,  732,  748,    2],\n",
      "        [ 380,    4,    5,    5,    8,    9,    2],\n",
      "        [ 866,    4,  870,  866,  767,  868,    2],\n",
      "        [ 784,  149,  789, 2204, 1010,  784,    2],\n",
      "        [1318, 1221, 1321, 1318, 1224, 1227,    2],\n",
      "        [2557, 2566, 2567, 2551,  720, 2557,    2],\n",
      "        [2204, 2120, 2210, 2204, 1010, 2211,    2],\n",
      "        [2504,  720, 2514, 2504, 2330, 2515,    2],\n",
      "        [   5,   59,   60, 1693,  720,    5,    2],\n",
      "        [ 360,  181,  370,  360,  256,  371,    2],\n",
      "        [ 726,  732,  740,  726,  732,  733,    2],\n",
      "        [2711, 2593, 2644, 2711, 2652, 2722,    2],\n",
      "        [2337, 2346, 2347, 2337, 2340, 2341,    2],\n",
      "        [1056, 1008, 1064, 1056, 1008, 1066,    2],\n",
      "        [1610, 1428, 1443, 1610, 1444, 1616,    2],\n",
      "        [1403, 1246, 1410, 1403, 1268, 1411,    2],\n",
      "        [1040, 1008, 1043, 1040, 1008, 1042,    2],\n",
      "        [ 387,  171,  248,  387,  214,  388,    2],\n",
      "        [  80,  480,  481,  447,  252,   80,    2],\n",
      "        [  93,    6,    5,    5,    8,   10,    2],\n",
      "        [2683, 2603, 2606, 2683, 2593, 2686,    2],\n",
      "        [2010, 1882, 2011, 2011,  720,  558,    2],\n",
      "        [ 464,  439,  440,  464,  473,  474,    2],\n",
      "        [1033, 1008, 1039, 1033, 1008, 1035,    2],\n",
      "        [2660, 2593, 2664, 2664, 2599, 2665,    2],\n",
      "        [  61,   14,   64,   61,   16,   65,    2]], device='cuda:0')\n",
      "Predicted idxs:\n",
      " tensor([[1468., 1910., 1910., 1910., 1910., 1910., 1910.],\n",
      "        [2333., 2333.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [1599.,  811.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [ 374., 1910., 1910.,  575.,  575.,  575.,  575.],\n",
      "        [2031., 1052.,  716.,  716.,  716.,  716.,  716.],\n",
      "        [ 811.,  811.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [  11.,  889.,  889., 2585., 2585., 2585., 2585.],\n",
      "        [2333., 2696., 2696., 1531., 1531., 1531., 1531.],\n",
      "        [2585., 2585., 2585., 2585., 2585., 2585., 2585.],\n",
      "        [ 811.,  811.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [ 919.,  811., 2585., 2585., 2585., 2585., 2585.],\n",
      "        [1599., 2588., 2588., 2588., 2588., 2588., 2588.],\n",
      "        [ 803.,  811.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [2588., 2588.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [1599., 2696., 2696., 2696., 1531., 1531., 2585.],\n",
      "        [1267.,  811.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [2588., 2588., 2585., 2585., 2585., 2585., 2585.],\n",
      "        [ 623.,  811.,  811.,  575., 2585., 2585., 2585.],\n",
      "        [1599., 1599.,  213.,  811.,  811.,  811.,  811.],\n",
      "        [1599.,  588.,  588., 1909., 1909., 1909., 1909.],\n",
      "        [2486., 1910., 1910., 1910., 2585., 2585., 2585.],\n",
      "        [2223., 1910., 1910., 1910., 1910., 1910., 1910.],\n",
      "        [ 811.,  811.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [2486., 2333., 2333., 2333., 1910.,  811.,  811.],\n",
      "        [ 811.,  811., 2585., 2585., 2585., 2585., 2585.],\n",
      "        [1531., 1531., 1531., 2585., 2585., 2585., 2585.],\n",
      "        [2031.,  811., 1910., 1910., 1910., 1910.,  575.],\n",
      "        [2588., 2588., 2588., 2588., 2588., 2588., 2588.],\n",
      "        [2333.,  588.,  588., 2585., 2585., 2585., 2585.],\n",
      "        [2585.,  992.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [ 264.,   11.,   11.,   11.,   11.,   11.,   11.],\n",
      "        [ 136., 1531., 1531., 1531., 2333., 2333., 2333.]], device='cuda:0')\n",
      "Return object: {'predicted_indices': tensor([[1468., 1910., 1910., 1910., 1910., 1910., 1910.],\n",
      "        [2333., 2333.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [1599.,  811.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [ 374., 1910., 1910.,  575.,  575.,  575.,  575.],\n",
      "        [2031., 1052.,  716.,  716.,  716.,  716.,  716.],\n",
      "        [ 811.,  811.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [  11.,  889.,  889., 2585., 2585., 2585., 2585.],\n",
      "        [2333., 2696., 2696., 1531., 1531., 1531., 1531.],\n",
      "        [2585., 2585., 2585., 2585., 2585., 2585., 2585.],\n",
      "        [ 811.,  811.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [ 919.,  811., 2585., 2585., 2585., 2585., 2585.],\n",
      "        [1599., 2588., 2588., 2588., 2588., 2588., 2588.],\n",
      "        [ 803.,  811.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [2588., 2588.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [1599., 2696., 2696., 2696., 1531., 1531., 2585.],\n",
      "        [1267.,  811.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [2588., 2588., 2585., 2585., 2585., 2585., 2585.],\n",
      "        [ 623.,  811.,  811.,  575., 2585., 2585., 2585.],\n",
      "        [1599., 1599.,  213.,  811.,  811.,  811.,  811.],\n",
      "        [1599.,  588.,  588., 1909., 1909., 1909., 1909.],\n",
      "        [2486., 1910., 1910., 1910., 2585., 2585., 2585.],\n",
      "        [2223., 1910., 1910., 1910., 1910., 1910., 1910.],\n",
      "        [ 811.,  811.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [2486., 2333., 2333., 2333., 1910.,  811.,  811.],\n",
      "        [ 811.,  811., 2585., 2585., 2585., 2585., 2585.],\n",
      "        [1531., 1531., 1531., 2585., 2585., 2585., 2585.],\n",
      "        [2031.,  811., 1910., 1910., 1910., 1910.,  575.],\n",
      "        [2588., 2588., 2588., 2588., 2588., 2588., 2588.],\n",
      "        [2333.,  588.,  588., 2585., 2585., 2585., 2585.],\n",
      "        [2585.,  992.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [ 264.,   11.,   11.,   11.,   11.,   11.,   11.],\n",
      "        [ 136., 1531., 1531., 1531., 2333., 2333., 2333.]], device='cuda:0'), 'loss': 55.45837354660034, 'predicted_words': ['\"27 June 2015\" 253260.0 (millimetres) 253260.0 (millimetres) 253260.0 (millimetres) 253260.0 (millimetres) 253260.0 (millimetres) 253260.0 (millimetres) ', '\"10R/28L\" \"10R/28L\" Solanaceae Solanaceae Solanaceae Solanaceae Solanaceae ', '523329000.0 (kilometres) Solanaceae Solanaceae Solanaceae Solanaceae Solanaceae Solanaceae ', 'Imst 253260.0 (millimetres) 253260.0 (millimetres) Big_Hero_6_(film) Big_Hero_6_(film) Big_Hero_6_(film) Big_Hero_6_(film) ', 'subsidiary Columbus,_Ohio 1920-01-01 1920-01-01 1920-01-01 1920-01-01 1920-01-01 ', 'Solanaceae Solanaceae Solanaceae Solanaceae Solanaceae Solanaceae Solanaceae ', 'Native_Americans_in_the_United_States \"Warm  or cold\" \"Warm  or cold\" Frederick_County,_Maryland Frederick_County,_Maryland Frederick_County,_Maryland Frederick_County,_Maryland ', '\"10R/28L\" Manchester Manchester Walter_Baade Walter_Baade Walter_Baade Walter_Baade ', 'Frederick_County,_Maryland Frederick_County,_Maryland Frederick_County,_Maryland Frederick_County,_Maryland Frederick_County,_Maryland Frederick_County,_Maryland Frederick_County,_Maryland ', 'Solanaceae Solanaceae Solanaceae Solanaceae Solanaceae Solanaceae Solanaceae ', '\"4.8\"^^<http://dbpedia.org/datatype/gram> Solanaceae Frederick_County,_Maryland Frederick_County,_Maryland Frederick_County,_Maryland Frederick_County,_Maryland Frederick_County,_Maryland ', '523329000.0 (kilometres) Turkish_lira Turkish_lira Turkish_lira Turkish_lira Turkish_lira Turkish_lira ', 'Javanese_cuisine Solanaceae Solanaceae Solanaceae Solanaceae Solanaceae Solanaceae ', 'Turkish_lira Turkish_lira Solanaceae Solanaceae Solanaceae Solanaceae Solanaceae ', '523329000.0 (kilometres) Manchester Manchester Manchester Walter_Baade Walter_Baade Frederick_County,_Maryland ', 'HIV Solanaceae Solanaceae Solanaceae Solanaceae Solanaceae Solanaceae ', 'Turkish_lira Turkish_lira Frederick_County,_Maryland Frederick_County,_Maryland Frederick_County,_Maryland Frederick_County,_Maryland Frederick_County,_Maryland ', 'rector Solanaceae Solanaceae Big_Hero_6_(film) Frederick_County,_Maryland Frederick_County,_Maryland Frederick_County,_Maryland ', '523329000.0 (kilometres) 523329000.0 (kilometres) Olusegun_Obasanjo Solanaceae Solanaceae Solanaceae Solanaceae ', '523329000.0 (kilometres) Bibbo_Bibbowski Bibbo_Bibbowski \"2013-03-11\"^^xsd:date \"2013-03-11\"^^xsd:date \"2013-03-11\"^^xsd:date \"2013-03-11\"^^xsd:date ', '\"11.8872\"^^xsd:double 253260.0 (millimetres) 253260.0 (millimetres) 253260.0 (millimetres) Frederick_County,_Maryland Frederick_County,_Maryland Frederick_County,_Maryland ', 'Christian_Panucci 253260.0 (millimetres) 253260.0 (millimetres) 253260.0 (millimetres) 253260.0 (millimetres) 253260.0 (millimetres) 253260.0 (millimetres) ', 'Solanaceae Solanaceae Solanaceae Solanaceae Solanaceae Solanaceae Solanaceae ', '\"11.8872\"^^xsd:double \"10R/28L\" \"10R/28L\" \"10R/28L\" 253260.0 (millimetres) Solanaceae Solanaceae ', 'Solanaceae Solanaceae Frederick_County,_Maryland Frederick_County,_Maryland Frederick_County,_Maryland Frederick_County,_Maryland Frederick_County,_Maryland ', 'Walter_Baade Walter_Baade Walter_Baade Frederick_County,_Maryland Frederick_County,_Maryland Frederick_County,_Maryland Frederick_County,_Maryland ', 'subsidiary Solanaceae 253260.0 (millimetres) 253260.0 (millimetres) 253260.0 (millimetres) 253260.0 (millimetres) Big_Hero_6_(film) ', 'Turkish_lira Turkish_lira Turkish_lira Turkish_lira Turkish_lira Turkish_lira Turkish_lira ', '\"10R/28L\" Bibbo_Bibbowski Bibbo_Bibbowski Frederick_County,_Maryland Frederick_County,_Maryland Frederick_County,_Maryland Frederick_County,_Maryland ', 'Frederick_County,_Maryland Mondelez_International Solanaceae Solanaceae Solanaceae Solanaceae Solanaceae ', 'Colin_Powell Native_Americans_in_the_United_States Native_Americans_in_the_United_States Native_Americans_in_the_United_States Native_Americans_in_the_United_States Native_Americans_in_the_United_States Native_Americans_in_the_United_States ', 'Williamson_County,_Texas Walter_Baade Walter_Baade Walter_Baade \"10R/28L\" \"10R/28L\" \"10R/28L\" ']}\n",
      "Predicted texts: ['\"27 June 2015\" 253260.0 (millimetres) 253260.0 (millimetres) 253260.0 (millimetres) 253260.0 (millimetres) 253260.0 (millimetres) 253260.0 (millimetres) ', '\"10R/28L\" \"10R/28L\" Solanaceae Solanaceae Solanaceae Solanaceae Solanaceae ', '523329000.0 (kilometres) Solanaceae Solanaceae Solanaceae Solanaceae Solanaceae Solanaceae ', 'Imst 253260.0 (millimetres) 253260.0 (millimetres) Big_Hero_6_(film) Big_Hero_6_(film) Big_Hero_6_(film) Big_Hero_6_(film) ', 'subsidiary Columbus,_Ohio 1920-01-01 1920-01-01 1920-01-01 1920-01-01 1920-01-01 ', 'Solanaceae Solanaceae Solanaceae Solanaceae Solanaceae Solanaceae Solanaceae ', 'Native_Americans_in_the_United_States \"Warm  or cold\" \"Warm  or cold\" Frederick_County,_Maryland Frederick_County,_Maryland Frederick_County,_Maryland Frederick_County,_Maryland ', '\"10R/28L\" Manchester Manchester Walter_Baade Walter_Baade Walter_Baade Walter_Baade ', 'Frederick_County,_Maryland Frederick_County,_Maryland Frederick_County,_Maryland Frederick_County,_Maryland Frederick_County,_Maryland Frederick_County,_Maryland Frederick_County,_Maryland ', 'Solanaceae Solanaceae Solanaceae Solanaceae Solanaceae Solanaceae Solanaceae ', '\"4.8\"^^<http://dbpedia.org/datatype/gram> Solanaceae Frederick_County,_Maryland Frederick_County,_Maryland Frederick_County,_Maryland Frederick_County,_Maryland Frederick_County,_Maryland ', '523329000.0 (kilometres) Turkish_lira Turkish_lira Turkish_lira Turkish_lira Turkish_lira Turkish_lira ', 'Javanese_cuisine Solanaceae Solanaceae Solanaceae Solanaceae Solanaceae Solanaceae ', 'Turkish_lira Turkish_lira Solanaceae Solanaceae Solanaceae Solanaceae Solanaceae ', '523329000.0 (kilometres) Manchester Manchester Manchester Walter_Baade Walter_Baade Frederick_County,_Maryland ', 'HIV Solanaceae Solanaceae Solanaceae Solanaceae Solanaceae Solanaceae ', 'Turkish_lira Turkish_lira Frederick_County,_Maryland Frederick_County,_Maryland Frederick_County,_Maryland Frederick_County,_Maryland Frederick_County,_Maryland ', 'rector Solanaceae Solanaceae Big_Hero_6_(film) Frederick_County,_Maryland Frederick_County,_Maryland Frederick_County,_Maryland ', '523329000.0 (kilometres) 523329000.0 (kilometres) Olusegun_Obasanjo Solanaceae Solanaceae Solanaceae Solanaceae ', '523329000.0 (kilometres) Bibbo_Bibbowski Bibbo_Bibbowski \"2013-03-11\"^^xsd:date \"2013-03-11\"^^xsd:date \"2013-03-11\"^^xsd:date \"2013-03-11\"^^xsd:date ', '\"11.8872\"^^xsd:double 253260.0 (millimetres) 253260.0 (millimetres) 253260.0 (millimetres) Frederick_County,_Maryland Frederick_County,_Maryland Frederick_County,_Maryland ', 'Christian_Panucci 253260.0 (millimetres) 253260.0 (millimetres) 253260.0 (millimetres) 253260.0 (millimetres) 253260.0 (millimetres) 253260.0 (millimetres) ', 'Solanaceae Solanaceae Solanaceae Solanaceae Solanaceae Solanaceae Solanaceae ', '\"11.8872\"^^xsd:double \"10R/28L\" \"10R/28L\" \"10R/28L\" 253260.0 (millimetres) Solanaceae Solanaceae ', 'Solanaceae Solanaceae Frederick_County,_Maryland Frederick_County,_Maryland Frederick_County,_Maryland Frederick_County,_Maryland Frederick_County,_Maryland ', 'Walter_Baade Walter_Baade Walter_Baade Frederick_County,_Maryland Frederick_County,_Maryland Frederick_County,_Maryland Frederick_County,_Maryland ', 'subsidiary Solanaceae 253260.0 (millimetres) 253260.0 (millimetres) 253260.0 (millimetres) 253260.0 (millimetres) Big_Hero_6_(film) ', 'Turkish_lira Turkish_lira Turkish_lira Turkish_lira Turkish_lira Turkish_lira Turkish_lira ', '\"10R/28L\" Bibbo_Bibbowski Bibbo_Bibbowski Frederick_County,_Maryland Frederick_County,_Maryland Frederick_County,_Maryland Frederick_County,_Maryland ', 'Frederick_County,_Maryland Mondelez_International Solanaceae Solanaceae Solanaceae Solanaceae Solanaceae ', 'Colin_Powell Native_Americans_in_the_United_States Native_Americans_in_the_United_States Native_Americans_in_the_United_States Native_Americans_in_the_United_States Native_Americans_in_the_United_States Native_Americans_in_the_United_States ', 'Williamson_County,_Texas Walter_Baade Walter_Baade Walter_Baade \"10R/28L\" \"10R/28L\" \"10R/28L\" ']\n",
      "Epoch: 1\n",
      "0. Condition: 2 triples per sentence.\n",
      "In predict:\n",
      "Targets:\n",
      " tensor([[1056, 1004, 1064, 1056, 1006, 1065,    2],\n",
      "        [1851, 1852, 1862, 1851, 1854, 1856,    2],\n",
      "        [2043, 2046, 2049, 2043, 1931, 1932,    2],\n",
      "        [ 784,  149,  789, 2204, 1010,  784,    2],\n",
      "        [2314, 2213, 2315, 2195, 1001, 2314,    2],\n",
      "        [1657, 1647, 1662, 1657, 1663, 1664,    2],\n",
      "        [1778,    4, 1776, 1775, 1739, 1778,    2],\n",
      "        [1009, 2134, 2284, 1009, 1203, 2285,    2],\n",
      "        [1584, 1435, 1585, 1584, 1576, 1586,    2],\n",
      "        [1610, 1428, 1443, 1610, 1444, 1616,    2],\n",
      "        [ 307,  171,  311,  307,  169,  312,    2],\n",
      "        [2444,  556, 2258, 2444, 2327, 2453,    2],\n",
      "        [1120, 1006, 1121, 1120, 1004, 1122,    2],\n",
      "        [2216, 1010, 2222, 2216, 1001, 2133,    2],\n",
      "        [2646, 2603, 2606, 2646,  435, 2612,    2],\n",
      "        [  27,    4,    5,    5,   26,   58,    2],\n",
      "        [  51,   26,   96,   50,   23,   51,    2],\n",
      "        [ 766,    4,  219,  766,  767,  768,    2],\n",
      "        [2273, 1203, 2122, 2273, 2120, 2277,    2],\n",
      "        [2660, 2593, 2664, 2664, 2599, 2665,    2],\n",
      "        [ 812,    4,  219,  812,  406,  817,    2],\n",
      "        [1671, 1647, 1672, 1671, 1646, 1673,    2],\n",
      "        [  80,   59,   99,   66,    6,   80,    2],\n",
      "        [  93,    6,    5,    5,    8,   11,    2],\n",
      "        [ 796,    4,  797,  797,   59,  800,    2],\n",
      "        [ 948,    4,  848,  848,  362,  850,    2],\n",
      "        [1489, 1428, 1494, 1489, 1435, 1492,    2],\n",
      "        [ 822,    4,  824,  824,   26,  828,    2],\n",
      "        [2504,  720, 2514, 2504, 2330, 2515,    2],\n",
      "        [ 948,  406,  848,  848,  149,  953,    2],\n",
      "        [2531, 2330, 2535, 2535, 1258, 2539,    2],\n",
      "        [2551,  635,  655, 2551, 2554, 2555,    2]], device='cuda:0')\n",
      "Predicted idxs:\n",
      " tensor([[ 588.,  811.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [2333.,  811.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [2486., 2588.,  200.,  200., 2585., 2585., 2585.],\n",
      "        [ 811.,  811.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [  11.,   11.,   11.,  811.,  811.,  811.,  811.],\n",
      "        [ 270., 1531., 1531.,  200.,  200.,  200.,  200.],\n",
      "        [2223.,  811.,  811.,  811.,  811., 2585., 2585.],\n",
      "        [1531., 1468.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [2588., 2632., 2632., 2632., 2585., 2585., 2585.],\n",
      "        [2486., 1910., 1910., 1910., 2585., 2585., 2585.],\n",
      "        [1910., 2585., 2585., 2585., 2585., 2585., 2585.],\n",
      "        [2588., 2585., 2585., 2585., 2585., 2585., 2585.],\n",
      "        [ 811.,  811.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [2333., 2333.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [1599., 1599., 1599., 1599., 1599., 1599., 1599.],\n",
      "        [2588.,  811.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [2333., 2585.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [1468., 1909., 1909., 1909., 1909., 1909., 1909.],\n",
      "        [1531., 1531., 1599., 1599., 1599., 1599., 1599.],\n",
      "        [ 811.,  811.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [ 136., 1164., 1164., 1164., 1164., 1164., 1164.],\n",
      "        [2588., 2588., 2588., 2169., 2169., 2169., 2169.],\n",
      "        [1531.,  811.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [1052., 1910., 1910., 1910., 1910., 1910., 1910.],\n",
      "        [1910., 2585., 2585., 2585., 2585., 2585., 2585.],\n",
      "        [2618., 1910., 2585., 2585., 2585., 2585., 2585.],\n",
      "        [2333., 2333., 2333.,  716.,  716.,  716.,  716.],\n",
      "        [1599.,   11.,   11.,   11.,  811.,  811., 2585.],\n",
      "        [2486., 1910., 1910., 1910., 1910., 1910., 1910.],\n",
      "        [2585., 2585., 2585., 2585., 2585., 2585., 2585.],\n",
      "        [2486., 2588., 2588., 2588., 2588., 2588.,  200.],\n",
      "        [ 632., 1902., 1759., 1759., 1759., 2585., 2585.]], device='cuda:0')\n",
      "Return object: {'predicted_indices': tensor([[ 588.,  811.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [2333.,  811.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [2486., 2588.,  200.,  200., 2585., 2585., 2585.],\n",
      "        [ 811.,  811.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [  11.,   11.,   11.,  811.,  811.,  811.,  811.],\n",
      "        [ 270., 1531., 1531.,  200.,  200.,  200.,  200.],\n",
      "        [2223.,  811.,  811.,  811.,  811., 2585., 2585.],\n",
      "        [1531., 1468.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [2588., 2632., 2632., 2632., 2585., 2585., 2585.],\n",
      "        [2486., 1910., 1910., 1910., 2585., 2585., 2585.],\n",
      "        [1910., 2585., 2585., 2585., 2585., 2585., 2585.],\n",
      "        [2588., 2585., 2585., 2585., 2585., 2585., 2585.],\n",
      "        [ 811.,  811.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [2333., 2333.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [1599., 1599., 1599., 1599., 1599., 1599., 1599.],\n",
      "        [2588.,  811.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [2333., 2585.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [1468., 1909., 1909., 1909., 1909., 1909., 1909.],\n",
      "        [1531., 1531., 1599., 1599., 1599., 1599., 1599.],\n",
      "        [ 811.,  811.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [ 136., 1164., 1164., 1164., 1164., 1164., 1164.],\n",
      "        [2588., 2588., 2588., 2169., 2169., 2169., 2169.],\n",
      "        [1531.,  811.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [1052., 1910., 1910., 1910., 1910., 1910., 1910.],\n",
      "        [1910., 2585., 2585., 2585., 2585., 2585., 2585.],\n",
      "        [2618., 1910., 2585., 2585., 2585., 2585., 2585.],\n",
      "        [2333., 2333., 2333.,  716.,  716.,  716.,  716.],\n",
      "        [1599.,   11.,   11.,   11.,  811.,  811., 2585.],\n",
      "        [2486., 1910., 1910., 1910., 1910., 1910., 1910.],\n",
      "        [2585., 2585., 2585., 2585., 2585., 2585., 2585.],\n",
      "        [2486., 2588., 2588., 2588., 2588., 2588.,  200.],\n",
      "        [ 632., 1902., 1759., 1759., 1759., 2585., 2585.]], device='cuda:0'), 'loss': 55.458362102508545, 'predicted_words': ['Bibbo_Bibbowski Solanaceae Solanaceae Solanaceae Solanaceae Solanaceae Solanaceae ', '\"10R/28L\" Solanaceae Solanaceae Solanaceae Solanaceae Solanaceae Solanaceae ', '\"11.8872\"^^xsd:double Turkish_lira Technical_Institute,_Kaduna Technical_Institute,_Kaduna Frederick_County,_Maryland Frederick_County,_Maryland Frederick_County,_Maryland ', 'Solanaceae Solanaceae Solanaceae Solanaceae Solanaceae Solanaceae Solanaceae ', 'Native_Americans_in_the_United_States Native_Americans_in_the_United_States Native_Americans_in_the_United_States Solanaceae Solanaceae Solanaceae Solanaceae ', 'Battle_of_Waterloo Walter_Baade Walter_Baade Technical_Institute,_Kaduna Technical_Institute,_Kaduna Technical_Institute,_Kaduna Technical_Institute,_Kaduna ', 'Christian_Panucci Solanaceae Solanaceae Solanaceae Solanaceae Frederick_County,_Maryland Frederick_County,_Maryland ', 'Walter_Baade \"27 June 2015\" Solanaceae Solanaceae Solanaceae Solanaceae Solanaceae ', 'Turkish_lira Electroacoustic_music Electroacoustic_music Electroacoustic_music Frederick_County,_Maryland Frederick_County,_Maryland Frederick_County,_Maryland ', '\"11.8872\"^^xsd:double 253260.0 (millimetres) 253260.0 (millimetres) 253260.0 (millimetres) Frederick_County,_Maryland Frederick_County,_Maryland Frederick_County,_Maryland ', '253260.0 (millimetres) Frederick_County,_Maryland Frederick_County,_Maryland Frederick_County,_Maryland Frederick_County,_Maryland Frederick_County,_Maryland Frederick_County,_Maryland ', 'Turkish_lira Frederick_County,_Maryland Frederick_County,_Maryland Frederick_County,_Maryland Frederick_County,_Maryland Frederick_County,_Maryland Frederick_County,_Maryland ', 'Solanaceae Solanaceae Solanaceae Solanaceae Solanaceae Solanaceae Solanaceae ', '\"10R/28L\" \"10R/28L\" Solanaceae Solanaceae Solanaceae Solanaceae Solanaceae ', '523329000.0 (kilometres) 523329000.0 (kilometres) 523329000.0 (kilometres) 523329000.0 (kilometres) 523329000.0 (kilometres) 523329000.0 (kilometres) 523329000.0 (kilometres) ', 'Turkish_lira Solanaceae Solanaceae Solanaceae Solanaceae Solanaceae Solanaceae ', '\"10R/28L\" Frederick_County,_Maryland Solanaceae Solanaceae Solanaceae Solanaceae Solanaceae ', '\"27 June 2015\" \"2013-03-11\"^^xsd:date \"2013-03-11\"^^xsd:date \"2013-03-11\"^^xsd:date \"2013-03-11\"^^xsd:date \"2013-03-11\"^^xsd:date \"2013-03-11\"^^xsd:date ', 'Walter_Baade Walter_Baade 523329000.0 (kilometres) 523329000.0 (kilometres) 523329000.0 (kilometres) 523329000.0 (kilometres) 523329000.0 (kilometres) ', 'Solanaceae Solanaceae Solanaceae Solanaceae Solanaceae Solanaceae Solanaceae ', 'Williamson_County,_Texas Olympique_Lyonnais Olympique_Lyonnais Olympique_Lyonnais Olympique_Lyonnais Olympique_Lyonnais Olympique_Lyonnais ', 'Turkish_lira Turkish_lira Turkish_lira Jorge_Humberto_Rodríguez Jorge_Humberto_Rodríguez Jorge_Humberto_Rodríguez Jorge_Humberto_Rodríguez ', 'Walter_Baade Solanaceae Solanaceae Solanaceae Solanaceae Solanaceae Solanaceae ', 'Columbus,_Ohio 253260.0 (millimetres) 253260.0 (millimetres) 253260.0 (millimetres) 253260.0 (millimetres) 253260.0 (millimetres) 253260.0 (millimetres) ', '253260.0 (millimetres) Frederick_County,_Maryland Frederick_County,_Maryland Frederick_County,_Maryland Frederick_County,_Maryland Frederick_County,_Maryland Frederick_County,_Maryland ', 'Lotus_Eaters_(band) 253260.0 (millimetres) Frederick_County,_Maryland Frederick_County,_Maryland Frederick_County,_Maryland Frederick_County,_Maryland Frederick_County,_Maryland ', '\"10R/28L\" \"10R/28L\" \"10R/28L\" 1920-01-01 1920-01-01 1920-01-01 1920-01-01 ', '523329000.0 (kilometres) Native_Americans_in_the_United_States Native_Americans_in_the_United_States Native_Americans_in_the_United_States Solanaceae Solanaceae Frederick_County,_Maryland ', '\"11.8872\"^^xsd:double 253260.0 (millimetres) 253260.0 (millimetres) 253260.0 (millimetres) 253260.0 (millimetres) 253260.0 (millimetres) 253260.0 (millimetres) ', 'Frederick_County,_Maryland Frederick_County,_Maryland Frederick_County,_Maryland Frederick_County,_Maryland Frederick_County,_Maryland Frederick_County,_Maryland Frederick_County,_Maryland ', '\"11.8872\"^^xsd:double Turkish_lira Turkish_lira Turkish_lira Turkish_lira Turkish_lira Technical_Institute,_Kaduna ', 'Kerala \"2009-03-22\"^^xsd:date Ethiopia Ethiopia Ethiopia Frederick_County,_Maryland Frederick_County,_Maryland ']}\n",
      "Predicted texts: ['Bibbo_Bibbowski Solanaceae Solanaceae Solanaceae Solanaceae Solanaceae Solanaceae ', '\"10R/28L\" Solanaceae Solanaceae Solanaceae Solanaceae Solanaceae Solanaceae ', '\"11.8872\"^^xsd:double Turkish_lira Technical_Institute,_Kaduna Technical_Institute,_Kaduna Frederick_County,_Maryland Frederick_County,_Maryland Frederick_County,_Maryland ', 'Solanaceae Solanaceae Solanaceae Solanaceae Solanaceae Solanaceae Solanaceae ', 'Native_Americans_in_the_United_States Native_Americans_in_the_United_States Native_Americans_in_the_United_States Solanaceae Solanaceae Solanaceae Solanaceae ', 'Battle_of_Waterloo Walter_Baade Walter_Baade Technical_Institute,_Kaduna Technical_Institute,_Kaduna Technical_Institute,_Kaduna Technical_Institute,_Kaduna ', 'Christian_Panucci Solanaceae Solanaceae Solanaceae Solanaceae Frederick_County,_Maryland Frederick_County,_Maryland ', 'Walter_Baade \"27 June 2015\" Solanaceae Solanaceae Solanaceae Solanaceae Solanaceae ', 'Turkish_lira Electroacoustic_music Electroacoustic_music Electroacoustic_music Frederick_County,_Maryland Frederick_County,_Maryland Frederick_County,_Maryland ', '\"11.8872\"^^xsd:double 253260.0 (millimetres) 253260.0 (millimetres) 253260.0 (millimetres) Frederick_County,_Maryland Frederick_County,_Maryland Frederick_County,_Maryland ', '253260.0 (millimetres) Frederick_County,_Maryland Frederick_County,_Maryland Frederick_County,_Maryland Frederick_County,_Maryland Frederick_County,_Maryland Frederick_County,_Maryland ', 'Turkish_lira Frederick_County,_Maryland Frederick_County,_Maryland Frederick_County,_Maryland Frederick_County,_Maryland Frederick_County,_Maryland Frederick_County,_Maryland ', 'Solanaceae Solanaceae Solanaceae Solanaceae Solanaceae Solanaceae Solanaceae ', '\"10R/28L\" \"10R/28L\" Solanaceae Solanaceae Solanaceae Solanaceae Solanaceae ', '523329000.0 (kilometres) 523329000.0 (kilometres) 523329000.0 (kilometres) 523329000.0 (kilometres) 523329000.0 (kilometres) 523329000.0 (kilometres) 523329000.0 (kilometres) ', 'Turkish_lira Solanaceae Solanaceae Solanaceae Solanaceae Solanaceae Solanaceae ', '\"10R/28L\" Frederick_County,_Maryland Solanaceae Solanaceae Solanaceae Solanaceae Solanaceae ', '\"27 June 2015\" \"2013-03-11\"^^xsd:date \"2013-03-11\"^^xsd:date \"2013-03-11\"^^xsd:date \"2013-03-11\"^^xsd:date \"2013-03-11\"^^xsd:date \"2013-03-11\"^^xsd:date ', 'Walter_Baade Walter_Baade 523329000.0 (kilometres) 523329000.0 (kilometres) 523329000.0 (kilometres) 523329000.0 (kilometres) 523329000.0 (kilometres) ', 'Solanaceae Solanaceae Solanaceae Solanaceae Solanaceae Solanaceae Solanaceae ', 'Williamson_County,_Texas Olympique_Lyonnais Olympique_Lyonnais Olympique_Lyonnais Olympique_Lyonnais Olympique_Lyonnais Olympique_Lyonnais ', 'Turkish_lira Turkish_lira Turkish_lira Jorge_Humberto_Rodríguez Jorge_Humberto_Rodríguez Jorge_Humberto_Rodríguez Jorge_Humberto_Rodríguez ', 'Walter_Baade Solanaceae Solanaceae Solanaceae Solanaceae Solanaceae Solanaceae ', 'Columbus,_Ohio 253260.0 (millimetres) 253260.0 (millimetres) 253260.0 (millimetres) 253260.0 (millimetres) 253260.0 (millimetres) 253260.0 (millimetres) ', '253260.0 (millimetres) Frederick_County,_Maryland Frederick_County,_Maryland Frederick_County,_Maryland Frederick_County,_Maryland Frederick_County,_Maryland Frederick_County,_Maryland ', 'Lotus_Eaters_(band) 253260.0 (millimetres) Frederick_County,_Maryland Frederick_County,_Maryland Frederick_County,_Maryland Frederick_County,_Maryland Frederick_County,_Maryland ', '\"10R/28L\" \"10R/28L\" \"10R/28L\" 1920-01-01 1920-01-01 1920-01-01 1920-01-01 ', '523329000.0 (kilometres) Native_Americans_in_the_United_States Native_Americans_in_the_United_States Native_Americans_in_the_United_States Solanaceae Solanaceae Frederick_County,_Maryland ', '\"11.8872\"^^xsd:double 253260.0 (millimetres) 253260.0 (millimetres) 253260.0 (millimetres) 253260.0 (millimetres) 253260.0 (millimetres) 253260.0 (millimetres) ', 'Frederick_County,_Maryland Frederick_County,_Maryland Frederick_County,_Maryland Frederick_County,_Maryland Frederick_County,_Maryland Frederick_County,_Maryland Frederick_County,_Maryland ', '\"11.8872\"^^xsd:double Turkish_lira Turkish_lira Turkish_lira Turkish_lira Turkish_lira Technical_Institute,_Kaduna ', 'Kerala \"2009-03-22\"^^xsd:date Ethiopia Ethiopia Ethiopia Frederick_County,_Maryland Frederick_County,_Maryland ']\n",
      "Train losses: [55.45837354660034, 55.458362102508545]\n"
     ]
    }
   ],
   "source": [
    "# Free CUDA memory\n",
    "if str(device) == 'cuda':\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "# Train\n",
    "train_losses, val_losses, encoder, decoder, rdf_vocab, word2idx, idx2word = training(train, dev, epochs=2)\n",
    "print('Train losses:', train_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test\n",
    "### Used exclusively for evaluation on test data after training is fuly finished"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation - Bleu Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(\n",
    "    data, \n",
    "    encoder, decoder,\n",
    "    rdf_vocab, word2idx, idx2word,\n",
    "    embedding_dim=300,\n",
    "    minibatch_size = 20,\n",
    "):\n",
    "    \n",
    "    # Construct RDF vocab\n",
    "    # vocab_count, word2idx, idx2word = rdf_vocab_constructor(data)\n",
    "    len_x = [len(dataset) for dataset in data]\n",
    "\n",
    "    # Perform own train step for each nr of triples per sentence separately\n",
    "    for i, nt in enumerate(range(MIN_NUM_TRIPLES, MAX_NUM_TRIPLES+1)):\n",
    "        print(str(i) + '. Condition:', nt, 'triples per sentence.')\n",
    "        \n",
    "        y_pred = []\n",
    "        y_true = [] # TO DO this should be list of lists and outside loop so that you get a y_pred and y_true for each nr of triples\n",
    "        \n",
    "        for batch in range(0, len_x[i], minibatch_size):\n",
    "\n",
    "            batch_end = min(len(data[i]), batch+minibatch_size)\n",
    "            \n",
    "            # Number of tokens to be predicted (per batch element)\n",
    "            num_preds = nt*3+1 # = nr triples * 3 + stop_token \n",
    "\n",
    "            # Construct proper minibatch\n",
    "            inputs = [x['text'] for x in data[i][batch:batch_end]]\n",
    "            targets = torch.ones([minibatch_size, num_preds], dtype=int).to(device)\n",
    "\n",
    "            #print('Inputs:', inputs)\n",
    "            #print('Targets:', targets)\n",
    "\n",
    "            for mb_i, idx in enumerate(range(batch, batch_end)):\n",
    "                #print('Text:', train_data[i][idx]['text'])\n",
    "                #print('Triple:', train_data[i][idx]['triple'])\n",
    "                for t, token in enumerate(data[i][idx]['triple']):\n",
    "                    targets[mb_i, t] = word2idx[token] if token in word2idx else 1\n",
    "            targets[:, -1] = 2  # 2 = Stop word index\n",
    "            \n",
    "            targets_text = [tuple(x['triple']) for x in data[i][batch:batch+minibatch_size]]\n",
    "\n",
    "            # Predict\n",
    "            ret_object = predict(\n",
    "                inputs,\n",
    "                rdf_vocab,              # Decoder's word embeddings\n",
    "                word2idx,               # \n",
    "                idx2word,               # \n",
    "                encoder,                # \n",
    "                decoder,                # \n",
    "                tokenizer,              # \n",
    "                None,                   # \n",
    "                max_len=num_preds,      # Nr of tokens to be predicted\n",
    "                batch_size=batch_end - batch,          # \n",
    "                compute_grads=False,     # \n",
    "                targets=targets,        # \n",
    "                return_textual=False     # Whether to return predictions in index-form (default) or as textual strings\n",
    "            )\n",
    "            \n",
    "            y_true = y_true + targets_text\n",
    "            y_pred = y_pred + [tuple(idx2word[i.item()] for i in x[:-1]) for x in ret_object['predicted_indices']]\n",
    "            \n",
    "    return y_true, y_pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. Condition: 2 triples per sentence.\n",
      "In predict:\n",
      "Targets:\n",
      " tensor([[ 277,  362, 1100, 2694,  179,  277,    2],\n",
      "        [2590, 2597, 2592, 2592, 2593, 2669,    2],\n",
      "        [2654,  220, 2656, 2656,  362, 2754,    2],\n",
      "        [2744, 2591, 2749, 2744, 2597, 2748,    2],\n",
      "        [2730, 2593, 2661, 2730, 2652, 2737,    2],\n",
      "        [2730, 2615, 2734, 2730, 2615, 2733,    2],\n",
      "        [2711, 2593, 2724, 2711, 2607, 2725,    2],\n",
      "        [2711, 2615, 2715, 2711, 2615, 2712,    2],\n",
      "        [2694,  171,  570, 2694,  220, 2696,    2],\n",
      "        [2687, 2593, 2692, 2692, 2599, 2596,    2],\n",
      "        [2694,  171,  570, 2694,  220, 2696,    2],\n",
      "        [2687,  171,  277, 2687,  220, 2691,    2],\n",
      "        [2683, 2593, 2643, 2683, 2603, 2604,    2],\n",
      "        [2673, 2593, 2669, 2669, 2599, 2678,    2],\n",
      "        [2673, 2593, 2669, 2669, 2599, 2661,    2],\n",
      "        [2673,  171, 2675, 2673, 2603, 2604,    2],\n",
      "        [2660, 1645,    5,    5,    8,    9,    2],\n",
      "        [2660, 2593, 2664, 2664, 2599, 2661,    2],\n",
      "        [2654, 2652, 2659, 2654,  171, 2657,    2],\n",
      "        [2646, 2593, 2636, 2636, 2641, 2643,    2]], device='cuda:0')\n",
      "Predicted idxs:\n",
      " tensor([[1599.,  811.,   11.,   11.,   11., 1599., 1599.],\n",
      "        [ 588.,  811.,  811.,  811.,  811., 2585., 2585.],\n",
      "        [ 811., 2585., 2585., 2585., 2585., 2585., 2585.],\n",
      "        [ 811.,  811.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [1599.,  136., 1909., 1909., 1909., 2585., 2585.],\n",
      "        [ 588.,  811.,  811.,  811.,  811.,  811., 2585.],\n",
      "        [ 623.,  811.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [2031., 1910.,  716.,  716.,  716.,  716.,  716.],\n",
      "        [ 811., 2618., 2618., 2618., 2618., 2618., 2618.],\n",
      "        [2585.,  811.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [1599.,  811.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [2585., 2585.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [2632., 2632.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [1599., 1599.,  811.,  811., 2585., 2585., 2585.],\n",
      "        [2031., 2031., 2031., 2031., 2031., 2031., 2031.],\n",
      "        [2585., 2585., 2585., 2585., 2585., 2585., 2585.],\n",
      "        [2031., 2588., 2588., 2588., 2588., 2588., 2588.],\n",
      "        [ 811.,  811.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [2585., 2031.,  811.,  811.,  811.,  811.,  575.],\n",
      "        [2588., 2588., 1759., 1759., 2585., 2585., 2585.]], device='cuda:0')\n",
      "In predict:\n",
      "Targets:\n",
      " tensor([[2633, 2593, 2636, 2636, 2599, 2644,    2],\n",
      "        [2633, 2593, 2636, 2636, 2641, 2642,    2],\n",
      "        [2614, 2593, 2628, 2614, 2607, 2629,    2],\n",
      "        [2614, 2615, 2623, 2614, 2593, 2626,    2],\n",
      "        [2601, 2613,   96, 2601, 1645,    5,    2],\n",
      "        [2601, 2613,   96, 2601, 1645,    5,    2],\n",
      "        [2590, 2595, 2592, 2592, 2593, 2596,    2],\n",
      "        [2586,  314, 2588, 2568,  720, 2586,    2],\n",
      "        [2562,  720, 2585, 2559, 2561, 2562,    2],\n",
      "        [2574, 1970, 2576, 2574, 2571, 2577,    2],\n",
      "        [2568, 2569, 2570, 2568, 2571, 2572,    2],\n",
      "        [2559, 2552, 2560, 2559,  635, 2563,    2],\n",
      "        [2441,    6,    5, 2437,  720, 2441,    2],\n",
      "        [2416,  945, 2549, 2504, 2550, 2416,    2],\n",
      "        [2531,  445, 2535, 2531, 2537, 2538,    2],\n",
      "        [2531, 2330, 2535, 2531, 2360, 2536,    2],\n",
      "        [2528, 2323,  298,  298,    4,  301,    2],\n",
      "        [2517, 2330, 2523, 2523, 2525,    1,    2],\n",
      "        [2517,  445, 2523, 2523, 2524, 2522,    2],\n",
      "        [2517,  445, 2523, 2517, 2340, 2519,    2]], device='cuda:0')\n",
      "Predicted idxs:\n",
      " tensor([[2644., 2588.,  575.,  575.,  575.,  575.,  575.],\n",
      "        [1599.,  811.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [ 575.,  575.,  588.,  811.,  811.,  811.,  811.],\n",
      "        [2172., 1070.,  575., 1909., 1909., 1909., 2585.],\n",
      "        [2575., 1759., 1759., 1759., 1759., 1759., 1759.],\n",
      "        [1468., 1759., 1759., 1759., 1759., 1759., 1759.],\n",
      "        [2031.,  811.,  811., 2488., 2488., 2488., 2488.],\n",
      "        [ 588.,   11.,   11.,  811.,  811., 1599., 1599.],\n",
      "        [1599., 2588., 2588., 2588., 2696., 2585., 2585.],\n",
      "        [1494., 1910., 1910., 1910., 1910., 1910., 1910.],\n",
      "        [1910., 1910., 1910., 1910., 1910., 1910., 1910.],\n",
      "        [2588., 2588., 2588., 2588., 2588., 2588., 2588.],\n",
      "        [2333.,  374.,  374.,  374.,  374.,  374.,  374.],\n",
      "        [ 270., 2588., 2588., 2618., 2618., 2618., 2618.],\n",
      "        [ 278., 1902., 2588., 2588.,  374.,  374.,  374.],\n",
      "        [2486., 2588., 2588., 2588., 2588., 2588., 2588.],\n",
      "        [2211., 2333., 2333., 2333., 2333., 2333., 2585.],\n",
      "        [2333., 2333., 1267.,  811.,  811.,  811.,  811.],\n",
      "        [2333., 2333., 2333., 2333., 2333.,  811.,  811.],\n",
      "        [1599., 1599., 1599.,  716.,  811.,  811.,  811.]], device='cuda:0')\n",
      "In predict:\n",
      "Targets:\n",
      " tensor([[2504, 2327,    1, 2504, 2508, 2416,    2],\n",
      "        [2504, 2510, 2416, 2504, 2331, 2512,    2],\n",
      "        [2504, 2510, 2416, 2504, 2331, 2511,    2],\n",
      "        [2496,  720, 2502, 2496, 2340, 2500,    2],\n",
      "        [2480, 2323, 2481, 2481,    4,    1,    2],\n",
      "        [2480, 2323, 2481, 2481,    4,    1,    2],\n",
      "        [2480, 2323, 2481, 2481, 2482, 2483,    2],\n",
      "        [2460,  720,   13,   13,  137, 2466,    2],\n",
      "        [2444,  556, 2258, 2258,  362, 2452,    2],\n",
      "        [2444, 2450, 2446, 2444, 2360, 2447,    2],\n",
      "        [2414, 2327, 2423, 2414, 2418, 2343,    2],\n",
      "        [2399, 2330, 2086, 2086, 2407,    1,    2],\n",
      "        [2399, 2330, 2086, 2086, 2407,    1,    2],\n",
      "        [2399, 2330, 2086, 2086, 2407, 2408,    2],\n",
      "        [2399,  720, 2396, 2399, 2327, 2405,    2],\n",
      "        [2380,  720, 2387, 2380, 2381, 2382,    2],\n",
      "        [2380,  720,  631, 2380, 2384, 2386,    2],\n",
      "        [2369, 2327, 2379, 2369,  720, 2376,    2],\n",
      "        [2369,  445, 2378, 2369,  720, 2375,    2],\n",
      "        [2356, 2327, 2362, 2356,  720, 2358,    2]], device='cuda:0')\n",
      "Predicted idxs:\n",
      " tensor([[ 588.,  588.,  588., 1599., 1599., 1599., 2618.],\n",
      "        [  72., 2333., 2333., 2333., 1910., 1910., 1910.],\n",
      "        [ 889.,  588.,  278.,  278.,  278., 2585., 2585.],\n",
      "        [2333., 2172.,  884.,  884., 2585., 2585., 2585.],\n",
      "        [2486., 2588., 2588., 2588., 2588., 2588., 2588.],\n",
      "        [2588., 1910., 1910.,  811.,  811.,  811.,  811.],\n",
      "        [2486., 2588., 2588., 2588., 2588., 2588., 2588.],\n",
      "        [2333., 2588., 2588.,  811., 1759., 1759., 1759.],\n",
      "        [2588., 2588., 2588., 2588., 2588., 2585., 2585.],\n",
      "        [2588., 2588., 2585., 2585., 2585., 2585., 2585.],\n",
      "        [1839., 2486., 2486., 1910., 1910., 1910., 1910.],\n",
      "        [2333., 2333., 2333., 2333.,  811.,  811.,  811.],\n",
      "        [2333., 2333., 2333., 2333., 2333., 2333., 2333.],\n",
      "        [2333., 2333., 2333.,  811.,  811.,  811.,  811.],\n",
      "        [1599., 1599., 1909., 1910., 1910., 1910., 1910.],\n",
      "        [2223., 2333., 2588., 2588., 2588., 2588., 2588.],\n",
      "        [2588.,  884.,  884.,  884.,  884.,  884.,  884.],\n",
      "        [1267., 1267., 1910., 1910., 1910., 1910., 1910.],\n",
      "        [1267., 1267., 2588., 2585., 2585., 2585., 2585.],\n",
      "        [2632., 2632., 2632.,  811.,  811.,  811.,  811.]], device='cuda:0')\n",
      "In predict:\n",
      "Targets:\n",
      " tensor([[2356,  720, 2359, 2359,    4,  219,    2],\n",
      "        [2356,  720, 2359, 2356, 2327, 2362,    2],\n",
      "        [2348,  556, 2351, 2348, 2323, 2352,    2],\n",
      "        [2337, 2323,    3,    3,   23,    7,    2],\n",
      "        [2322, 2330, 2329, 2322, 2331, 2333,    2],\n",
      "        [2322,  445, 2326, 2322, 2327, 2328,    2],\n",
      "        [2322,  720, 2324, 2324,    6,  664,    2],\n",
      "        [1002, 2213, 2320, 2143, 1001, 1002,    2],\n",
      "        [2247,  720,  298, 2240, 1010, 2247,    2],\n",
      "        [2300, 1028, 2306, 2300, 2120, 2302,    2],\n",
      "        [2287, 2120, 2298, 2287, 1203, 2299,    2],\n",
      "        [1009, 1028, 2280, 2280, 1008, 2282,    2],\n",
      "        [2257, 1010, 2258, 2258, 2259, 2261,    2],\n",
      "        [2234, 2134, 2238, 2234, 1203, 2239,    2],\n",
      "        [2234, 1028, 2235, 2235, 1008, 2236,    2],\n",
      "        [2216, 1010, 2222, 2216, 1001, 2133,    2],\n",
      "        [2204, 1203, 2215, 2204, 2134, 2206,    2],\n",
      "        [2204, 1010,  784,  784,   59,  787,    2],\n",
      "        [2204, 2157, 2205, 2204, 2120, 2206,    2],\n",
      "        [2195, 1028, 2201, 2201, 1008, 2194,    2]], device='cuda:0')\n",
      "Predicted idxs:\n",
      " tensor([[1599., 2585., 2585., 2585., 2585., 2585., 2585.],\n",
      "        [2671., 2333.,  889.,  889.,  811.,  811.,  811.],\n",
      "        [1599., 2588., 2588., 2588., 2588., 2588., 2588.],\n",
      "        [2333., 2333., 2333., 2333.,  811.,  811.,  811.],\n",
      "        [1910., 1910., 2632.,  575.,  575.,  575.,  575.],\n",
      "        [2486., 1910., 1910., 1910., 1910., 1910., 1910.],\n",
      "        [1910., 1910., 1910., 1910., 1599., 1599., 1910.],\n",
      "        [ 811.,  811.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [2588., 1910., 2585., 2585., 2585., 2585., 2585.],\n",
      "        [ 278., 1599., 1599., 1599., 1599., 2588., 2588.],\n",
      "        [1910.,  278.,  278.,  811.,  811.,  811.,  811.],\n",
      "        [2297., 1910.,  575.,  575.,  575.,  575.,  575.],\n",
      "        [  11.,   11.,   11.,   11.,   11., 2585., 2585.],\n",
      "        [ 278.,  588.,  811., 1599., 1599., 1599., 1599.],\n",
      "        [1390., 1390.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [ 811.,  811.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [2333.,  811.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [ 992., 1267.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [1910., 1910., 1910., 1910., 1910., 1910., 1910.],\n",
      "        [ 575.,  575.,  575.,  575.,  575.,  278.,  278.]], device='cuda:0')\n",
      "In predict:\n",
      "Targets:\n",
      " tensor([[2195, 1010, 2198, 2195, 2120, 2199,    2],\n",
      "        [2181, 1028, 2189, 2189, 1008,    1,    2],\n",
      "        [2173,  720,  301,  301,  362, 2178,    2],\n",
      "        [2173,  720,  301,  301,  137, 2174,    2],\n",
      "        [2165, 1010,    1, 2165, 2120,  657,    2],\n",
      "        [2165, 1010,    1, 2165, 2120,  657,    2],\n",
      "        [2156, 1028, 2161, 2161, 1004, 2163,    2],\n",
      "        [2156, 1028, 2161, 2161, 1006, 2155,    2],\n",
      "        [2143, 1010, 2144, 2143, 1001, 1002,    2],\n",
      "        [2131, 1028, 2138, 2138, 1008, 2139,    2],\n",
      "        [2131, 1010,  784, 2131, 1001, 2133,    2],\n",
      "        [2123, 1203, 2122, 2123, 2120, 2125,    2],\n",
      "        [2123, 1001, 2124, 2123, 2120, 2125,    2],\n",
      "        [2114, 1203, 2119, 2114, 2120, 2121,    2],\n",
      "        [   5,  137,  138, 2081, 1927,    5,    2],\n",
      "        [2004, 1865, 2107, 1997, 1865, 2004,    2],\n",
      "        [1900,  720,    5, 1891, 1882, 1900,    2],\n",
      "        [2089, 1867, 2096, 2096, 1971, 2097,    2],\n",
      "        [2081, 1867, 2087, 2081, 1931, 2083,    2],\n",
      "        [2081, 1927,    5,    5,    8,   11,    2]], device='cuda:0')\n",
      "Predicted idxs:\n",
      " tensor([[ 575.,   11.,   11.,   11., 2585., 2585., 2585.],\n",
      "        [ 588.,  588.,  575.,  575.,  575.,  575.,  575.],\n",
      "        [ 647., 2333., 2333., 2333., 1421., 1421.,  270.],\n",
      "        [2588., 2588., 2588., 2588., 2588., 2588., 2588.],\n",
      "        [1599., 1910., 1910., 1910., 1910., 1910., 1910.],\n",
      "        [1599., 1910., 1910., 1910., 1910., 1910., 1910.],\n",
      "        [ 811.,  811.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [1599.,  811.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [2031.,  811.,  811., 2585., 2585., 2585., 2585.],\n",
      "        [2588.,  811.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [ 632.,  811.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [ 588.,  919.,  811., 2585., 2585., 2585., 2585.],\n",
      "        [1531.,  811.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [1531., 2588., 2585., 2585., 2585., 2585., 2585.],\n",
      "        [2588., 1759.,  200.,  200.,  200.,  200.,  811.],\n",
      "        [ 811., 1468., 1468., 1468., 1468., 1468., 1468.],\n",
      "        [2585., 2585., 2585., 2585., 2585., 2585., 2585.],\n",
      "        [1599., 1599.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [2588., 2588., 2588., 2585., 2585., 2585., 2585.],\n",
      "        [1531., 2486.,  200.,  200.,  200.,  200.,  200.]], device='cuda:0')\n",
      "In predict:\n",
      "Targets:\n",
      " tensor([[2081, 1927,    5, 2081, 1931, 2084,    2],\n",
      "        [2081, 1927,    5, 2081, 1931, 2082,    2],\n",
      "        [2071, 1865, 2077, 2071, 1942,  277,    2],\n",
      "        [ 365,   26,  361, 1956,    4,  365,    2],\n",
      "        [2043, 1931, 2048, 2048, 2051, 2052,    2],\n",
      "        [2043, 1931, 1932, 2043, 2044, 2045,    2],\n",
      "        [2043, 2046, 2047, 2043, 1931, 2048,    2],\n",
      "        [2019, 2020, 2029, 2019, 1852, 2030,    2],\n",
      "        [2005, 1877, 2006, 2005, 2007, 2008,    2],\n",
      "        [1997, 1865, 2002, 1997, 1865, 2001,    2],\n",
      "        [1997, 1854, 1863, 1997, 1852, 1965,    2],\n",
      "        [1997, 1865, 2004, 1997, 1942, 2000,    2],\n",
      "        [1997, 1942, 2003, 1997, 1865, 2001,    2],\n",
      "        [1997, 1942, 2000, 1997, 1865, 2002,    2],\n",
      "        [1990, 1992, 1991, 1990, 1874, 1994,    2],\n",
      "        [1990, 1874, 1991, 1990, 1992, 1993,    2],\n",
      "        [1978, 1867, 1984, 1978, 1852, 1980,    2],\n",
      "        [1978, 1867, 1984, 1978, 1852, 1986,    2],\n",
      "        [1963, 1976, 1977, 1963, 1854, 1966,    2],\n",
      "        [1963, 1976, 1977, 1963, 1854, 1966,    2]], device='cuda:0')\n",
      "Predicted idxs:\n",
      " tensor([[1531.,  200.,  200.,  200.,  200.,  200.,  200.],\n",
      "        [2588., 2588., 2588., 2588., 2588., 2588., 2588.],\n",
      "        [2333.,  811.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [2588.,  811.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [ 632., 2588., 2588.,  811., 2585., 2585., 2585.],\n",
      "        [2588., 2588., 2588., 2588., 2585., 2585., 2585.],\n",
      "        [ 919., 2585., 2585., 2585., 2585., 2585., 2585.],\n",
      "        [2237., 1276.,  213.,  213.,  213.,  213.,  213.],\n",
      "        [ 811.,  811., 2585., 2585., 2585., 2585., 2585.],\n",
      "        [ 575.,  811.,  811.,  811., 2488., 2488., 2488.],\n",
      "        [ 811.,  811.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [1599.,  811.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [ 811.,  811.,  811., 2488., 2488., 2488., 2488.],\n",
      "        [ 811.,  811.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [  11., 2031.,  575.,  575.,  575.,  575.,  575.],\n",
      "        [ 588.,  588.,  588.,  588.,  278.,  278.,  278.],\n",
      "        [ 811.,  811.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [ 811.,  811.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [ 811.,  811., 1910., 1910., 1910., 1910., 1910.],\n",
      "        [ 811.,  811., 1910., 1910., 1910., 1910., 1910.]], device='cuda:0')\n",
      "In predict:\n",
      "Targets:\n",
      " tensor([[1963, 1973, 1974, 1963, 1854, 1966,    2],\n",
      "        [1968,  709, 1969, 1963, 1970, 1968,    2],\n",
      "        [1956, 1874, 1957, 1956,    4,  365,    2],\n",
      "        [1941, 1942, 1951, 1941, 1944, 1949,    2],\n",
      "        [1941, 1942, 1950, 1941, 1944, 1949,    2],\n",
      "        [1941, 1942, 1948, 1941, 1944, 1945,    2],\n",
      "        [1941, 1942, 1946, 1941, 1944, 1945,    2],\n",
      "        [1941, 1942, 1943, 1941, 1944, 1945,    2],\n",
      "        [1851, 1865, 1866, 1866, 1867, 1869,    2],\n",
      "        [1851, 1852, 1853, 1851, 1854, 1857,    2],\n",
      "        [1818,  720, 1831, 1831,    4,    5,    2],\n",
      "        [1818,  720, 1829, 1818, 1811, 1830,    2],\n",
      "        [1818,  720, 1826, 1818, 1815, 1827,    2],\n",
      "        [1805,  720, 1808, 1805, 1809, 1810,    2],\n",
      "        [1799,  720, 1802, 1799,    4, 1803,    2],\n",
      "        [1799,    4, 1767, 1799, 1800, 1801,    2],\n",
      "        [1794,  689,  631,  631,  149, 1797,    2],\n",
      "        [1781, 1793, 1785, 1785,    4,    5,    2],\n",
      "        [1781,  720, 1789, 1781, 1663, 1790,    2],\n",
      "        [1775,    4, 1776, 1775, 1739, 1777,    2]], device='cuda:0')\n",
      "Predicted idxs:\n",
      " tensor([[ 811.,  811.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [ 811.,  811.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [1531.,  200.,  200.,  200.,  200.,  200.,  200.],\n",
      "        [ 278.,  215.,  215., 1239.,  514.,  514.,  514.],\n",
      "        [1599.,  811.,  811.,  811., 2488., 2488., 2488.],\n",
      "        [ 514., 2585., 2585., 2585., 2585., 2585., 2585.],\n",
      "        [1599., 2488., 2488., 2488., 2488., 2488., 2488.],\n",
      "        [ 811.,  811.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [2536., 2488., 2488., 2488., 2488., 2488., 2488.],\n",
      "        [2074., 1531.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [2588., 1389., 1389.,  811.,  811.,  811.,  811.],\n",
      "        [1599., 1599., 1910., 1910., 1910., 1910., 1910.],\n",
      "        [1566., 1910., 1910., 1910., 1910., 1910., 1910.],\n",
      "        [2575.,  889., 2585., 2585., 2585., 2585., 2585.],\n",
      "        [1599., 1909.,   11.,   11.,   11.,  811.,  811.],\n",
      "        [1599.,  811.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [1759., 1759., 2585., 2585., 2585., 2585., 2585.],\n",
      "        [1599., 1599., 2585., 2585., 2585., 2585., 2585.],\n",
      "        [1599., 2588., 2588., 2588., 2588., 2588., 2588.],\n",
      "        [ 136.,  811.,  811.,  811.,  811.,  811.,  811.]], device='cuda:0')\n",
      "In predict:\n",
      "Targets:\n",
      " tensor([[1764, 1698, 1765, 1764,  720, 1767,    2],\n",
      "        [1754,    4, 1759, 1759,   59, 1761,    2],\n",
      "        [1738, 1640, 1748, 1738, 1646, 1742,    2],\n",
      "        [1735,  734,    1, 1729, 1793, 1735,    2],\n",
      "        [1735,  734,    1, 1729, 1793, 1735,    2],\n",
      "        [1729, 1731, 1732, 1729, 1733, 1734,    2],\n",
      "        [1729, 1640, 1730, 1729, 1647, 1650,    2],\n",
      "        [1718, 1663, 1728, 1718,  720, 1726,    2],\n",
      "        [1703,  720,  993,  993,    6, 1709,    2],\n",
      "        [1693,  720, 1697, 1693, 1685, 1700,    2],\n",
      "        [1693, 1685,    1, 1693, 1647, 1696,    2],\n",
      "        [1693, 1685,    1, 1693, 1647, 1696,    2],\n",
      "        [1693, 1694, 1695, 1693, 1647, 1696,    2],\n",
      "        [1682,  720,  277,  277,  314, 1691,    2],\n",
      "        [1671,  720,  341,  341, 1675, 1676,    2],\n",
      "        [1671, 1647, 1672, 1671,  720, 1674,    2],\n",
      "        [1657,  720, 1665, 1665,    8, 1668,    2],\n",
      "        [1639,  720, 1644, 1639, 1640, 1641,    2],\n",
      "        [1639,  720, 1644, 1639, 1640, 1641,    2],\n",
      "        [1630, 1456, 1634, 1630, 1428, 1566,    2]], device='cuda:0')\n",
      "Predicted idxs:\n",
      " tensor([[1531., 1531., 2585., 2585., 2585., 2585., 2585.],\n",
      "        [2333., 1531., 1531., 1531., 1531., 1531., 1531.],\n",
      "        [1599., 2333., 2588., 2588., 2588., 2588., 2588.],\n",
      "        [ 613., 2588., 2588., 2588., 2588., 2588., 2588.],\n",
      "        [ 756., 2588., 2588., 2588., 2588., 2588., 2588.],\n",
      "        [1599., 1531., 2588.,  811.,  811.,  811.,  811.],\n",
      "        [2169., 2169., 2169., 2169., 2169., 2585., 2585.],\n",
      "        [2333.,  811.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [ 798., 1531., 2585., 2585., 2585., 2585., 2585.],\n",
      "        [2486.,  811.,  811.,  811.,  811., 2588., 2588.],\n",
      "        [ 588., 2588., 2588., 2588., 2588., 2588., 2588.],\n",
      "        [1910., 1910., 2585., 2585., 2585., 2585., 2585.],\n",
      "        [1531., 1531., 1531., 1531., 1531., 1531., 1531.],\n",
      "        [1468., 2588., 2588., 2588., 2588., 2588., 2588.],\n",
      "        [1910., 2333., 2585., 2585., 2585., 2585., 2585.],\n",
      "        [2486., 2333., 2333., 2333., 2588., 2588., 2588.],\n",
      "        [1599., 1910., 1910., 2184., 2184., 2184., 2184.],\n",
      "        [1965., 1965.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [1965., 1965.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [1052.,  716.,  716.,  716.,  716.,  716.,  716.]], device='cuda:0')\n",
      "In predict:\n",
      "Targets:\n",
      " tensor([[1621, 1547, 1626, 1621, 1435, 1623,    2],\n",
      "        [1621, 1435, 1623, 1621, 1576, 1624,    2],\n",
      "        [1600, 1456,    1, 1600, 1428, 1506,    2],\n",
      "        [1600, 1456,    1, 1600, 1428, 1506,    2],\n",
      "        [1584, 1444, 1588, 1584, 1435, 1585,    2],\n",
      "        [1573, 1444, 1581, 1573, 1435, 1574,    2],\n",
      "        [1573, 1435, 1574, 1573, 1576, 1577,    2],\n",
      "        [1560, 1428, 1567, 1560, 1446, 1568,    2],\n",
      "        [1551, 1426, 1557, 1557,  252, 1558,    2],\n",
      "        [1540, 1497, 1546, 1540, 1435, 1542,    2],\n",
      "        [1528, 1426, 1531, 1531,  252, 1534,    2],\n",
      "        [1517, 1446,    1, 1517, 1428, 1555,    2],\n",
      "        [1517, 1446,    1, 1517, 1428, 1555,    2],\n",
      "        [1517, 1426, 1521, 1521, 1524, 1014,    2],\n",
      "        [1509, 1477, 1511, 1509, 1428, 1506,    2],\n",
      "        [1489, 1456, 1499, 1489, 1466, 1500,    2],\n",
      "        [1475, 1446, 1479, 1475, 1428, 1480,    2],\n",
      "        [1451, 1444, 1458, 1451, 1446, 1459,    2],\n",
      "        [1451, 1428, 1452, 1451, 1446, 1453,    2],\n",
      "        [1425, 1426, 1430, 1425, 1428, 1429,    2]], device='cuda:0')\n",
      "Predicted idxs:\n",
      " tensor([[2588., 2588., 2588., 2588., 2585., 2585., 2585.],\n",
      "        [2588., 2588., 2585., 2585., 2585., 2585., 2585.],\n",
      "        [ 200.,  200., 2585., 2585., 2585., 2585., 2585.],\n",
      "        [ 514., 1409., 1052., 1052., 1052., 1052., 1052.],\n",
      "        [  11., 1599.,  796.,  796.,  796.,  796.,  796.],\n",
      "        [2588., 2588., 2588., 2588., 2585., 2585., 2585.],\n",
      "        [2618., 2618., 2618., 2618., 2618., 2618.,  575.],\n",
      "        [ 715.,  200., 1759., 1759., 1759., 2585., 2585.],\n",
      "        [  11.,   11.,   11., 2585., 2585., 2585., 2585.],\n",
      "        [1052., 2333.,  716.,  716.,  716.,  716.,  716.],\n",
      "        [1572.,  811.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [1599., 1599., 1599., 1599., 1599., 1599., 1599.],\n",
      "        [1599., 1599., 1599., 1599., 1599., 1599., 1599.],\n",
      "        [ 811.,   11.,  575.,  575.,  575.,  575.,  575.],\n",
      "        [2585., 2585., 2585., 2585., 2585., 2585., 2585.],\n",
      "        [ 697., 2486., 2585., 2585., 2585., 2585., 2585.],\n",
      "        [1409., 2333., 2008., 2008., 2008., 2008.,  618.],\n",
      "        [2486., 2585., 2585., 2585., 2585., 2585., 2585.],\n",
      "        [2618.,  200.,  219.,  219.,  219., 2585., 2585.],\n",
      "        [2333., 2585., 2585., 2585., 2585., 2585., 2585.]], device='cuda:0')\n",
      "In predict:\n",
      "Targets:\n",
      " tensor([[   5,  362,  150, 1230,    4,    5,    2],\n",
      "        [   5,   26,   58, 1332,    4,    5,    2],\n",
      "        [1403, 1246, 1410, 1403, 1412, 1413,    2],\n",
      "        [1395, 1221, 1397, 1395, 1241, 1398,    2],\n",
      "        [1350, 1303,    1, 1350, 1219, 1394,    2],\n",
      "        [1350, 1303,    1, 1350, 1219, 1394,    2],\n",
      "        [1350, 1221, 1346, 1350, 1288, 1390,    2],\n",
      "        [1377, 1248, 1378, 1377, 1246, 1379,    2],\n",
      "        [1369, 1246, 1373, 1369, 1254, 1374,    2],\n",
      "        [1369, 1274, 1370, 1369, 1246, 1371,    2],\n",
      "        [1359, 1256, 1367, 1367, 1258, 1368,    2],\n",
      "        [1338, 1248, 1341, 1338, 1246, 1342,    2],\n",
      "        [1338, 1251, 1339, 1338, 1246, 1340,    2],\n",
      "        [1332,   59,   60,   60, 1243, 1244,    2],\n",
      "        [1325,    4,    5,    5,    8,   11,    2],\n",
      "        [1325,    4,    5,    5,    8,    9,    2],\n",
      "        [1325, 1219, 1326, 1325, 1224, 1227,    2],\n",
      "        [1318,    4,    5,    5,   59,   60,    2],\n",
      "        [1309,   59,   60,   60, 1243, 1244,    2],\n",
      "        [1286, 1224, 1227, 1286, 1219, 1290,    2]], device='cuda:0')\n",
      "Predicted idxs:\n",
      " tensor([[2585., 1531., 1531., 1531., 1531., 1531., 1531.],\n",
      "        [ 811.,  811.,  811.,  811.,  811., 2585., 2585.],\n",
      "        [2223., 2223., 1910., 1910., 1910., 1910., 1910.],\n",
      "        [2585., 2585., 2585., 2585., 2585., 2585., 2585.],\n",
      "        [2585., 2585., 2585., 2585., 2585., 2585., 2585.],\n",
      "        [2585., 2585., 2585., 2585., 2585., 2585., 2585.],\n",
      "        [2031., 2031., 2333., 2333., 2333., 2333., 2333.],\n",
      "        [ 347., 2585., 2585., 2585., 2585., 2585., 2585.],\n",
      "        [2588.,  811.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [1380.,  588.,  588.,  588.,  588.,  588.,  588.],\n",
      "        [ 780., 2172., 2172., 2172., 2172., 2172., 2172.],\n",
      "        [ 588., 1909.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [1059., 2333., 1910.,  716.,  716.,  716.,  716.],\n",
      "        [2585., 1531., 1531., 1531., 1531., 1531., 1531.],\n",
      "        [2588., 2588., 1599., 1599., 1599., 1599., 1599.],\n",
      "        [2588., 2588., 2588., 1599., 1599., 1599., 1599.],\n",
      "        [ 575., 2031.,  200.,  200., 1609., 1609., 1609.],\n",
      "        [1531., 2074., 1239., 1239., 1239., 1239., 1239.],\n",
      "        [1531., 1531., 1910.,  811.,  811.,  811.,  811.],\n",
      "        [1239., 1910., 1052., 1052., 1052., 1052., 1052.]], device='cuda:0')\n",
      "In predict:\n",
      "Targets:\n",
      " tensor([[1272, 1277, 1278, 1278, 1281, 1282,    2],\n",
      "        [1272, 1246, 1273, 1272, 1254, 1276,    2],\n",
      "        [1260,    4,  277, 1260, 1256, 1270,    2],\n",
      "        [1245, 1256, 1257, 1257,  149, 1259,    2],\n",
      "        [1230, 1241, 1242, 1230, 1228, 1237,    2],\n",
      "        [1230, 1221, 1226, 1230, 1219, 1236,    2],\n",
      "        [1230, 1221, 1235, 1230, 1228, 1237,    2],\n",
      "        [1230, 1221, 1235, 1230, 1219, 1236,    2],\n",
      "        [1218, 1228, 1234, 1218, 1221, 1222,    2],\n",
      "        [1218, 1224, 1227, 1218, 1221, 1222,    2],\n",
      "        [1218, 1219, 1220, 1218, 1221, 1223,    2],\n",
      "        [1212, 1095, 1213, 1117, 1008, 1212,    2],\n",
      "        [1159, 1006, 1164, 1164, 1076, 1208,    2],\n",
      "        [1014,  149, 1100, 1047,  171, 1014,    2],\n",
      "        [1014,  619, 1193, 1013,  171, 1014,    2],\n",
      "        [1174, 1008, 1177, 1174,  171, 1014,    2],\n",
      "        [1174,  171, 1175, 1174, 1008, 1177,    2],\n",
      "        [1003, 1007, 1173, 1003, 1008, 1167,    2],\n",
      "        [1159, 1008, 1160, 1159, 1008, 1163,    2],\n",
      "        [1148, 1008, 1155, 1155, 1028, 1157,    2]], device='cuda:0')\n",
      "Predicted idxs:\n",
      " tensor([[ 811.,  811.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [2588., 2588., 2588., 2588., 2588., 2588., 2588.],\n",
      "        [1599., 1910., 1910., 1910., 1910., 1909., 1909.],\n",
      "        [ 732.,  732., 1910.,  811.,  811.,  811.,  811.],\n",
      "        [  11.,   11.,  575.,  575.,  575.,  575.,  575.],\n",
      "        [2644.,  200., 2585., 2585., 2585., 2585., 2585.],\n",
      "        [1531.,  811.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [1531., 1531., 1531., 1531., 1531., 1531., 1531.],\n",
      "        [1531., 2585.,  811.,  811., 2585., 2585., 2585.],\n",
      "        [ 121., 2172., 2172., 2172., 2172., 2585., 2585.],\n",
      "        [2031., 1052., 1531.,  716.,  716.,  716.,  716.],\n",
      "        [ 811.,  811.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [1572.,  811.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [ 811.,  811.,  811.,  811., 1909., 2585., 2585.],\n",
      "        [2297.,  811.,  811.,  811.,  575.,  575.,  575.],\n",
      "        [1599., 1599.,  811.,  811.,  811., 2696., 2696.],\n",
      "        [ 588.,   11.,   11.,   11.,   11.,   11.,   11.],\n",
      "        [ 811.,  811.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [ 588.,  811.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [1531.,  632., 1902.,  632., 2588., 2588., 2588.]], device='cuda:0')\n",
      "In predict:\n",
      "Targets:\n",
      " tensor([[1148, 1008, 1154, 1148, 1008, 1150,    2],\n",
      "        [1148, 1008, 1154, 1148, 1008, 1153,    2],\n",
      "        [1117, 1008, 1118, 1118, 1010, 1119,    2],\n",
      "        [1110, 1008, 1112, 1112, 1007, 1109,    2],\n",
      "        [1098,  220, 1099, 1099,  149, 1100,    2],\n",
      "        [1091, 1079, 1094, 1094,  556,   27,    2],\n",
      "        [1091,  240,    1, 1091,  171, 1093,    2],\n",
      "        [1091,  240,    1, 1091,  171, 1093,    2],\n",
      "        [1068, 1008, 1071, 1068, 1008, 1075,    2],\n",
      "        [1056, 1008, 1057, 1057, 1028, 1058,    2],\n",
      "        [1047, 1054, 1055, 1047,  171, 1014,    2],\n",
      "        [1033, 1008, 1039, 1033, 1008, 1035,    2],\n",
      "        [1024, 1008, 1027, 1027, 1028, 1030,    2],\n",
      "        [1013,  345, 1018, 1013,  171, 1014,    2],\n",
      "        [ 793,  775,  811,  783,  767,  793,    2],\n",
      "        [ 721,   59,  355,  936,    4,  721,    2],\n",
      "        [ 784,   26,  225,  783,    4,  784,    2],\n",
      "        [ 892,  905,  983,  890,  767,  892,    2],\n",
      "        [ 972,  790,  980,  972,  855,  874,    2],\n",
      "        [ 972,  855,  874,  874,  790,  970,    2]], device='cuda:0')\n",
      "Predicted idxs:\n",
      " tensor([[1910., 1910., 2585., 2585., 2585., 2585., 2585.],\n",
      "        [ 588., 2585., 2585., 2585., 2585., 2585., 2585.],\n",
      "        [  11.,  811.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [1599., 1599., 1531., 1531., 1531., 1531., 1531.],\n",
      "        [ 811.,  588.,  588.,  588., 2585., 2585., 2585.],\n",
      "        [2585., 2585., 2585., 2585., 2585., 2585., 2585.],\n",
      "        [1599., 2585., 2585., 2585., 2585., 2585., 2585.],\n",
      "        [1599., 2585., 2585., 2585., 2585., 2585., 2585.],\n",
      "        [ 588.,  588.,  588.,  588.,  588., 1909., 1909.],\n",
      "        [ 278., 1910., 1910., 1910., 1910., 1910., 1910.],\n",
      "        [2488., 2585., 1524.,  588.,  588.,  588.,  588.],\n",
      "        [1599.,  588.,  889.,  889., 2585., 2585., 2585.],\n",
      "        [1468.,  811.,  889., 1909., 1909., 1909., 1909.],\n",
      "        [1468., 2632., 1524., 1524., 1524.,  588.,  588.],\n",
      "        [1468.,  811.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [2585.,  811.,  811.,  811.,  811.,  811., 2585.],\n",
      "        [ 811.,  811.,  811.,  811.,  811., 2585., 2585.],\n",
      "        [1468.,  811.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [1599., 1910., 1910., 1910., 1910., 2585., 2585.],\n",
      "        [2588., 1531., 2585., 2585., 2585., 2585., 2585.]], device='cuda:0')\n",
      "In predict:\n",
      "Targets:\n",
      " tensor([[972, 855, 874, 972, 767, 977,   2],\n",
      "        [972,   4, 973, 973, 362, 979,   2],\n",
      "        [972,   4, 973, 973,  59,  81,   2],\n",
      "        [965, 767, 971, 965, 804, 969,   2],\n",
      "        [954, 406, 652, 652, 149, 959,   2],\n",
      "        [936,   4, 721, 936, 767, 938,   2],\n",
      "        [936,   4, 721, 936, 767, 894,   2],\n",
      "        [936,   4, 721, 936, 767, 894,   2],\n",
      "        [915, 925, 926, 915, 920, 927,   2],\n",
      "        [915,   4, 871, 871, 149, 872,   2],\n",
      "        [915,   4, 871, 871,  59, 356,   2],\n",
      "        [840, 767, 903, 840,   4, 898,   2],\n",
      "        [840,   4, 898, 840, 767, 900,   2],\n",
      "        [890,   4, 797, 890, 767, 893,   2],\n",
      "        [876, 807, 877, 876, 855, 878,   2],\n",
      "        [866,   4, 867, 866, 767,   1,   2],\n",
      "        [866,   4, 867, 866, 767,   1,   2],\n",
      "        [858, 465, 859, 858, 767, 861,   2],\n",
      "        [851,   4,   5,   5,   8,   9,   2],\n",
      "        [841, 406, 824, 841, 767, 843,   2]], device='cuda:0')\n",
      "Predicted idxs:\n",
      " tensor([[1599.,  811.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [2585.,  811.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [2588., 2588., 2585., 2585., 2585., 2585., 2585.],\n",
      "        [1468.,  811.,  811.,  811.,  811., 2585., 2585.],\n",
      "        [2585., 2588., 2585., 2585., 2585., 2585., 2585.],\n",
      "        [ 270.,  811.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [2223.,  811.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [ 811.,  811.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [1531.,  811.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [2588.,  811.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [1910.,  811.,  811.,  811., 1910., 1910., 1910.],\n",
      "        [1599., 2588.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [2588.,  811.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [1910.,   11.,   11.,  811.,  811.,  811.,  811.],\n",
      "        [ 647., 1910., 1910., 1910., 1910., 1910., 1910.],\n",
      "        [2632.,  811.,  811.,  811.,  811.,  811., 2585.],\n",
      "        [2632.,  811.,  811.,  811.,  811.,  811., 2585.],\n",
      "        [1421., 1421., 1910., 1910., 1910., 1910., 1910.],\n",
      "        [2333., 1759., 1759., 1759., 1759., 1759., 1759.],\n",
      "        [2588.,  811.,  811.,  811.,  811.,  811.,  811.]], device='cuda:0')\n",
      "In predict:\n",
      "Targets:\n",
      " tensor([[841, 406, 847, 841, 767, 843,   2],\n",
      "        [822,   4, 824, 824, 149, 835,   2],\n",
      "        [822,   4, 824, 824,   8, 830,   2],\n",
      "        [812, 406, 819, 819, 149, 821,   2],\n",
      "        [812, 406, 817, 817, 149, 818,   2],\n",
      "        [812,   4, 219, 812, 767, 815,   2],\n",
      "        [796,   4, 797, 796, 767, 798,   2],\n",
      "        [783, 406, 795, 783, 767, 786,   2],\n",
      "        [783, 767, 793, 793, 777, 794,   2],\n",
      "        [783,   4, 784, 784, 149,   1,   2],\n",
      "        [783,   4, 784, 784,  59, 787,   2],\n",
      "        [766, 406, 780, 780, 149, 782,   2],\n",
      "        [754, 732, 764, 754, 720, 761,   2],\n",
      "        [754, 692, 763, 754, 732, 757,   2],\n",
      "        [754, 720, 760, 754, 732, 757,   2],\n",
      "        [754, 709, 755, 755,  42,  44,   2],\n",
      "        [741, 692, 745, 741, 732, 748,   2],\n",
      "        [741, 697, 742, 741, 699, 743,   2],\n",
      "        [726, 720, 721, 726, 703, 730,   2],\n",
      "        [726, 699, 727, 726, 703, 730,   2]], device='cuda:0')\n",
      "Predicted idxs:\n",
      " tensor([[2588., 2588., 1531., 2585., 2585., 2585., 2585.],\n",
      "        [1599., 1599., 2618., 2618., 2618., 2618., 2585.],\n",
      "        [2588., 2588., 2588.,  811.,  811.,  811.,  811.],\n",
      "        [ 992.,  588.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [2632., 2169.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [1599., 1599., 1910., 1910., 1910., 1910., 1910.],\n",
      "        [ 733.,  632.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [2333.,  811.,  811., 2588., 2588., 2588., 2588.],\n",
      "        [1421., 1910., 1910., 1910., 1910., 1910., 1910.],\n",
      "        [ 811.,  811.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [2588., 2588., 2588., 2588., 2588., 2588., 2588.],\n",
      "        [2632., 2585., 2585., 2585., 2585.,  811.,  811.],\n",
      "        [2333., 1910., 1910.,  811.,  575.,  575.,  575.],\n",
      "        [2333., 1910., 1910., 1910.,  575.,  575.,  575.],\n",
      "        [ 716.,  884., 2588., 2588., 2588.,  811.,  811.],\n",
      "        [2333., 2588., 2585., 2585., 2585., 2585., 2585.],\n",
      "        [ 716., 2588., 1599., 1599., 1599., 1599., 1599.],\n",
      "        [2588., 2588., 2588., 2588., 2588., 2588., 2588.],\n",
      "        [1599., 1599., 1599., 2618., 2618., 2618., 2618.],\n",
      "        [1599., 2585., 2585., 2585., 2585., 2585., 2585.]], device='cuda:0')\n",
      "In predict:\n",
      "Targets:\n",
      " tensor([[708, 724, 725, 708, 718, 719,   2],\n",
      "        [708, 690, 716, 708, 692, 717,   2],\n",
      "        [708, 709, 712, 708, 703, 713,   2],\n",
      "        [708, 709, 710, 708, 720, 721,   2],\n",
      "        [708, 709, 710, 708, 720, 721,   2],\n",
      "        [674, 628, 675, 674, 635, 676,   2],\n",
      "        [618,   8, 669, 670,   4, 618,   2],\n",
      "        [647, 490, 651, 647, 414, 652,   2],\n",
      "        [647, 628, 648, 647, 649, 650,   2],\n",
      "        [637, 641, 642, 637, 635, 644,   2],\n",
      "        [613, 509, 614, 613, 511, 615,   2],\n",
      "        [592, 513, 593, 593, 179, 138,   2],\n",
      "        [609, 513, 612, 609, 509, 611,   2],\n",
      "        [609, 513, 610, 609, 511, 612,   2],\n",
      "        [605, 179,   5, 600, 513, 605,   2],\n",
      "        [600, 511, 603, 600, 513, 602,   2],\n",
      "        [595, 513, 596, 595, 511, 598,   2],\n",
      "        [592, 511, 593, 593, 468, 594,   2],\n",
      "        [571, 577, 575, 575, 559, 580,   2],\n",
      "        [571, 577, 575, 575, 559, 579,   2]], device='cuda:0')\n",
      "Predicted idxs:\n",
      " tensor([[2588.,  811.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [1531., 2585., 2585., 2585., 2585., 2585., 2585.],\n",
      "        [1572.,  811.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [1572., 1572., 2585.,  811.,  811.,  811.,  811.],\n",
      "        [1572., 1572., 2585.,  811.,  811.,  811.,  811.],\n",
      "        [1910., 1910.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [2585., 2585., 2585., 2333., 2585., 2585., 2585.],\n",
      "        [1910., 1910., 1910., 1910., 1910., 1910., 1910.],\n",
      "        [1910., 1910.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [1421., 1421., 1421., 1910., 1910., 1910., 1910.],\n",
      "        [2074., 2488., 1759., 1759., 1759., 1759., 1759.],\n",
      "        [2632., 1524., 1524., 2585., 2585., 2585., 2585.],\n",
      "        [1599., 2585.,  588.,  588.,  588.,  588.,  588.],\n",
      "        [1531., 2031.,  588.,  588.,  588.,  588.,  588.],\n",
      "        [1519., 1759.,  588.,  588.,  588., 2585., 2585.],\n",
      "        [ 588.,  811., 1759., 2585., 2585., 2585., 2585.],\n",
      "        [ 811.,  811.,  811.,  811., 2585., 2585., 2585.],\n",
      "        [ 919., 1759., 2585., 2585., 2585., 2585., 2585.],\n",
      "        [ 811.,  811.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [1531., 1531., 1531., 1531., 1531., 1531., 2585.]], device='cuda:0')\n",
      "In predict:\n",
      "Targets:\n",
      " tensor([[571, 574, 575, 575, 559, 576,   2],\n",
      "        [571, 511, 572, 571, 513, 573,   2],\n",
      "        [553, 559, 568, 568, 171, 569,   2],\n",
      "        [543, 513, 544, 543, 509, 545,   2],\n",
      "        [535, 511, 536, 535, 513, 537,   2],\n",
      "        [531, 511, 532, 532, 179,   5,   2],\n",
      "        [526, 511, 529, 529, 179, 530,   2],\n",
      "        [521, 511, 524, 521, 509, 522,   2],\n",
      "        [518, 513, 519, 518, 511, 520,   2],\n",
      "        [508, 513, 514, 508, 511, 512,   2],\n",
      "        [463, 179,   5, 463, 171, 460,   2],\n",
      "        [450, 497, 498, 447, 171, 450,   2],\n",
      "        [485, 252, 492, 485, 439, 494,   2],\n",
      "        [485, 252, 492, 485, 342, 493,   2],\n",
      "        [464, 443, 471, 464, 437, 472,   2],\n",
      "        [447, 179,   5, 447, 240, 454,   2],\n",
      "        [447, 171, 450, 447, 179,   5,   2],\n",
      "        [431, 437, 438, 431, 439, 440,   2],\n",
      "        [291,  59, 428, 279, 179, 291,   2],\n",
      "        [291,   8, 426, 279, 179, 291,   2]], device='cuda:0')\n",
      "Predicted idxs:\n",
      " tensor([[2585., 2585., 2585., 2585., 2585., 2585., 2585.],\n",
      "        [1531., 1531.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [  11., 1910.,  811.,  811., 2585., 2585., 2585.],\n",
      "        [2585., 2585., 2585., 2585., 2585., 2585., 2585.],\n",
      "        [2585., 2585., 2585., 2585., 2585., 2585., 2585.],\n",
      "        [1910., 2486., 2585., 2585., 2585., 2585., 2585.],\n",
      "        [2585., 2585., 2585., 2585., 2585., 2585., 2585.],\n",
      "        [1909., 1421., 1421., 1421., 1421., 1421., 1421.],\n",
      "        [ 588.,  588., 2031., 2585., 2585., 2585., 2585.],\n",
      "        [2585., 2585., 2585., 2585., 2585., 2585., 2585.],\n",
      "        [2585.,  811.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [1531., 1531., 1531., 1531., 1531., 1531., 1531.],\n",
      "        [1531.,  811.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [2585., 2585.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [2074.,  811.,  811.,  811.,  811., 2585., 2585.],\n",
      "        [1389., 1389.,  200.,  200.,  200.,  200.,  200.],\n",
      "        [1910., 1910., 2618., 2618., 2618., 2618., 2618.],\n",
      "        [2632., 2632., 2632., 2333., 2333., 2333., 2333.],\n",
      "        [ 588.,  588.,  588.,  588.,  588.,  588.,  588.],\n",
      "        [2585.,  811.,  811.,  811.,  811., 1531., 1531.]], device='cuda:0')\n",
      "In predict:\n",
      "Targets:\n",
      " tensor([[205, 160, 425, 198, 204, 205,   2],\n",
      "        [404, 406, 415, 404, 211, 413,   2],\n",
      "        [404, 406, 412, 404, 414, 415,   2],\n",
      "        [404, 181, 410, 410, 149,   1,   2],\n",
      "        [404, 181, 410, 410, 149,   1,   2],\n",
      "        [396, 187, 401, 396, 214, 399,   2],\n",
      "        [380, 187, 385, 380, 169, 381,   2],\n",
      "        [380,   4,   5,   5,   8,  11,   2],\n",
      "        [295, 256, 293, 293, 171, 373,   2],\n",
      "        [353, 252, 358, 353, 171, 255,   2],\n",
      "        [353, 252, 357, 353, 171, 354,   2],\n",
      "        [339, 228, 348, 339, 211, 349,   2],\n",
      "        [339, 345, 346, 339, 240, 340,   2],\n",
      "        [296, 303, 302, 296, 187, 300,   2],\n",
      "        [279, 157, 288, 279, 155, 282,   2],\n",
      "        [279, 157, 288, 279, 155, 290,   2],\n",
      "        [279, 157, 288, 279, 155, 281,   2],\n",
      "        [261, 191, 278, 261, 171, 269,   2],\n",
      "        [261, 157, 262, 262, 160, 266,   2],\n",
      "        [216, 223, 224, 216, 171, 219,   2]], device='cuda:0')\n",
      "Predicted idxs:\n",
      " tensor([[ 811.,  811.,  811., 1909., 1909., 1909., 1909.],\n",
      "        [  11.,   11.,   11.,   11.,   11.,   11.,   11.],\n",
      "        [2428.,   11.,   11., 1599., 1599., 1599., 1599.],\n",
      "        [ 811.,  811.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [ 811.,  811.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [ 919., 1646., 1646., 1646., 1646., 1646., 1646.],\n",
      "        [2223.,  588.,  811.,  618.,  618.,  618.,  618.],\n",
      "        [ 811.,  811.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [2632., 2632.,  811., 2585., 2585., 2585., 2585.],\n",
      "        [ 811.,  811.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [2333., 2333., 1599., 1599., 1599., 1599., 1599.],\n",
      "        [ 811.,  811.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [ 811., 2333.,  884.,  884.,  884.,  884.,  884.],\n",
      "        [2583., 1421., 1910., 1910., 1910., 1910., 1910.],\n",
      "        [ 588.,  588.,  588.,  588.,  588.,  588.,  588.],\n",
      "        [ 811.,  588.,  588.,  588.,  588.,  588.,  588.],\n",
      "        [ 811.,  811.,  732., 2585., 2585., 2585., 2585.],\n",
      "        [1599., 1910.,  811.,  811.,  811.,  575.,  575.],\n",
      "        [2588., 2588., 2585., 2585., 2585., 2585., 2585.],\n",
      "        [2585., 2632., 2585., 2585., 2585., 2585., 2585.]], device='cuda:0')\n",
      "In predict:\n",
      "Targets:\n",
      " tensor([[216, 169, 217, 216, 171, 218,   2],\n",
      "        [186, 171, 188, 186, 187, 193,   2],\n",
      "        [186, 171, 188, 186, 181, 190,   2],\n",
      "        [168, 171, 174, 168, 171, 178,   2],\n",
      "        [154, 157, 159, 159, 160, 162,   2],\n",
      "        [154, 157, 159, 154, 155, 156,   2],\n",
      "        [145,  23, 152, 152,   4,   5,   2],\n",
      "        [  5,   8,  11, 127,   4,   5,   2],\n",
      "        [  5,   8,  10,  30,   4,   5,   2],\n",
      "        [  5,   8,  10,  24,   6,   5,   2],\n",
      "        [ 13,  26, 134, 103,   6,  13,   2],\n",
      "        [ 22,   4,   5,   5,   8,   9,   2],\n",
      "        [ 22,   4,   5,  22,  23,  21,   2],\n",
      "        [ 22,  16, 124,  22,  14, 125,   2],\n",
      "        [119,   6,   5,   5,  26,  58,   2],\n",
      "        [119,   4,   5,   5,   8,  10,   2],\n",
      "        [116,   4,   5,   5,   8,  11,   2],\n",
      "        [116,   4,   5,   5,   8,  10,   2],\n",
      "        [ 27,   4,   5,  27,   6,  25,   2],\n",
      "        [103,  16, 109, 103,  14, 110,   2]], device='cuda:0')\n",
      "Predicted idxs:\n",
      " tensor([[1910., 1910., 1910., 1910., 1910., 1910., 1910.],\n",
      "        [1531.,  811., 1909., 1909., 2585., 2585., 2585.],\n",
      "        [2618.,  811.,  811.,  811.,  811.,  811., 2585.],\n",
      "        [1599., 1599., 1910., 1910., 1910., 1910., 1910.],\n",
      "        [1599., 1599., 1599., 1599., 1599., 1599., 1599.],\n",
      "        [1599., 1599., 1599., 1599., 1599., 1599., 1599.],\n",
      "        [ 647., 1267., 2333., 2333., 2333., 2333., 2333.],\n",
      "        [2333., 1531., 1531., 1531., 1531., 1531., 1531.],\n",
      "        [1599., 1531., 1531., 1531., 1531., 1531., 1531.],\n",
      "        [2588., 2588., 1759., 1164., 1164., 1164., 1164.],\n",
      "        [1070., 1531., 1531., 1531., 1531., 1531., 2585.],\n",
      "        [2333., 2333., 1531., 1531., 1531., 1531., 1531.],\n",
      "        [ 136.,  811.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [1910., 1910., 1910., 1910., 1910., 1910., 1910.],\n",
      "        [2333.,  811.,  811.,  811.,  811.,  811.,  811.],\n",
      "        [1599., 1531., 1531., 1531., 1531., 1531., 1531.],\n",
      "        [2333., 2588., 2588., 2588., 1531., 1531., 1531.],\n",
      "        [2333., 2333., 2588., 2588., 1531., 1531., 1531.],\n",
      "        [2575., 1531., 1531., 1531., 1531., 1531., 1531.],\n",
      "        [2536., 2536., 1531., 1531., 2585., 2585., 2585.]], device='cuda:0')\n",
      "In predict:\n",
      "Targets:\n",
      " tensor([[103,   6, 104, 103,   6,  13,   2],\n",
      "        [ 66,  42,  82,  66,   6,  80,   2],\n",
      "        [ 66,   6,  79,  79,   6,  85,   2],\n",
      "        [ 66,   6,  80,  80,   4,   5,   2],\n",
      "        [ 61,   6,  63,  61,   4,   5,   2],\n",
      "        [ 30,   4,   5,   5,   8,   9,   2],\n",
      "        [ 24,   4,   5,   5,   8,  11,   2],\n",
      "        [ 21,   4,   5,  22,  23,  21,   2],\n",
      "        [  3,   4,   5,   5,   8,  11,   2],\n",
      "        [  3,   4,   5,   5,   8,  10,   2],\n",
      "        [  1,   1,   1,   1,   1,   1,   2],\n",
      "        [  1,   1,   1,   1,   1,   1,   2],\n",
      "        [  1,   1,   1,   1,   1,   1,   2],\n",
      "        [  1,   1,   1,   1,   1,   1,   2],\n",
      "        [  1,   1,   1,   1,   1,   1,   2],\n",
      "        [  1,   1,   1,   1,   1,   1,   2],\n",
      "        [  1,   1,   1,   1,   1,   1,   2],\n",
      "        [  1,   1,   1,   1,   1,   1,   2],\n",
      "        [  1,   1,   1,   1,   1,   1,   2],\n",
      "        [  1,   1,   1,   1,   1,   1,   2]], device='cuda:0')\n",
      "Predicted idxs:\n",
      " tensor([[ 405., 2172., 2172., 2172., 1910., 1910., 1910.],\n",
      "        [2585., 2585., 2585., 2585., 2585., 2585., 2585.],\n",
      "        [2333., 2333.,   11.,  374.,  374.,  374.,  374.],\n",
      "        [2588., 2333.,  374.,  374.,  374.,  374.,  374.],\n",
      "        [2333., 2333., 2585., 2585., 2585., 2585., 2585.],\n",
      "        [ 270., 2588., 1599., 1599., 1599., 1599., 1531.],\n",
      "        [ 796., 2588., 2588., 2588., 2588., 2588., 2588.],\n",
      "        [2333., 2333., 2333.,  200.,  200.,  200.,  200.],\n",
      "        [2333., 2588., 2588., 2588.,  200.,  200.,  200.],\n",
      "        [1910., 1910.,  716.,  716.,  716.,  716.,  716.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "if str(device) == 'cuda':\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "y_true, y_pred = inference(dev, encoder, decoder, rdf_vocab, word2idx, idx2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strict(target, prediction):\n",
    "    return target==predict\n",
    "\n",
    "def partial(target, prediction):\n",
    "    for t, p in zip(target, prediction):\n",
    "        if not p in t:\n",
    "            return False\n",
    "        \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from sklearn import metrics as skmetrics\n",
    "\n",
    "def evaluate(y_true, y_pred, compare=strict):\n",
    "    \n",
    "    y_pred = copy.copy(y_pred)\n",
    "    \n",
    "    for target, i in zip(y_true, range(len(y_pred))):\n",
    "        \n",
    "        if compare(target, y_pred[i]):\n",
    "            y_pred[i] = target\n",
    "            \n",
    "    y_true = list(map(lambda x : str(hash(x)), y_true))\n",
    "    y_pred = list(map(lambda x : str(hash(x)), y_pred))\n",
    "            \n",
    "    return skmetrics.classification_report(y_true, y_pred, digits=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      precision    recall  f1-score   support\n",
      "\n",
      "-1016422939606932485      0.000     0.000     0.000       1.0\n",
      "-1025870128829541935      0.000     0.000     0.000       1.0\n",
      "-1043062273057642093      0.000     0.000     0.000       0.0\n",
      "-1071905400282584653      0.000     0.000     0.000       0.0\n",
      " -107500563247651945      0.000     0.000     0.000       0.0\n",
      " -108377096120305081      0.000     0.000     0.000       1.0\n",
      "-1194560511365850915      0.000     0.000     0.000       1.0\n",
      "-1198035588448809744      0.000     0.000     0.000       1.0\n",
      "-1206190990298734777      0.000     0.000     0.000       0.0\n",
      "-1209568362898718444      0.000     0.000     0.000       1.0\n",
      "-1228890402996436310      0.000     0.000     0.000       0.0\n",
      "-1231553683019066793      0.000     0.000     0.000       0.0\n",
      "-1232819917207955220      0.000     0.000     0.000       1.0\n",
      "-1277726524583305919      0.000     0.000     0.000       0.0\n",
      "-1283963440972458868      0.000     0.000     0.000       1.0\n",
      "-1303304390983451084      0.000     0.000     0.000       2.0\n",
      "-1305155258778880037      0.000     0.000     0.000       0.0\n",
      " -133399120771068382      0.000     0.000     0.000       1.0\n",
      "-1340148986339836867      0.000     0.000     0.000       0.0\n",
      "-1368191775816640891      0.000     0.000     0.000       1.0\n",
      "-1376474054972632642      0.000     0.000     0.000       0.0\n",
      "-1408177565528891578      0.000     0.000     0.000       1.0\n",
      "-1414707403814378912      0.000     0.000     0.000       1.0\n",
      "-1428499049360678944      0.000     0.000     0.000       1.0\n",
      "-1448719968533206282      0.000     0.000     0.000       1.0\n",
      "-1527070564786295746      0.000     0.000     0.000       1.0\n",
      "-1552316105315077859      0.000     0.000     0.000       1.0\n",
      "-1645637941433346403      0.000     0.000     0.000       0.0\n",
      "-1656402292432324296      0.000     0.000     0.000       1.0\n",
      " -166874132066195584      0.000     0.000     0.000       1.0\n",
      " -167011109936585786      0.000     0.000     0.000       1.0\n",
      "-1704263881402662813      0.000     0.000     0.000       1.0\n",
      "-1789545923572543654      0.000     0.000     0.000       1.0\n",
      "-1796614297115445778      0.000     0.000     0.000       1.0\n",
      "-1926189032210527114      0.000     0.000     0.000       0.0\n",
      "-1933165099993843786      0.000     0.000     0.000       1.0\n",
      "-1933280368739300144      0.000     0.000     0.000       1.0\n",
      "-1935159312522914847      0.000     0.000     0.000       1.0\n",
      " -196579641055880256      0.000     0.000     0.000       0.0\n",
      "-1974605707758369897      0.000     0.000     0.000       0.0\n",
      "-1981356292677365388      0.000     0.000     0.000       0.0\n",
      " -201877864506839318      0.000     0.000     0.000       1.0\n",
      "-2021074720177968476      0.000     0.000     0.000       2.0\n",
      "-2059882235006175082      0.000     0.000     0.000       1.0\n",
      "-2073312483268423470      0.000     0.000     0.000       1.0\n",
      "-2105955393882672799      0.000     0.000     0.000       1.0\n",
      "-2139152324705004552      0.000     0.000     0.000       0.0\n",
      "-2193642790237505670      0.000     0.000     0.000       0.0\n",
      "-2273455060675116996      0.000     0.000     0.000       1.0\n",
      "-2293275614031651661      0.000     0.000     0.000       0.0\n",
      "-2302206522209678465      0.000     0.000     0.000       0.0\n",
      "-2333294134063068926      0.000     0.000     0.000       0.0\n",
      "-2335692231395504552      0.000     0.000     0.000       1.0\n",
      "-2341100346096230698      0.000     0.000     0.000       1.0\n",
      "-2359850917093940771      0.000     0.000     0.000       0.0\n",
      "-2366850159686158182      0.000     0.000     0.000       1.0\n",
      "-2406880536838803610      0.000     0.000     0.000       1.0\n",
      "-2424578603473884867      0.000     0.000     0.000       1.0\n",
      "-2424645241198408054      0.000     0.000     0.000       0.0\n",
      "-2481063531038114545      0.000     0.000     0.000       0.0\n",
      "-2502563340831801208      0.000     0.000     0.000       1.0\n",
      "-2530718741872879619      0.000     0.000     0.000       1.0\n",
      "   -2555548507948498      0.000     0.000     0.000       1.0\n",
      "-2571507273163797415      0.000     0.000     0.000       0.0\n",
      "-2574726233409433537      0.000     0.000     0.000       1.0\n",
      "-2594321627560817899      0.000     0.000     0.000       0.0\n",
      "-2634970238255402188      0.000     0.000     0.000       1.0\n",
      "-2638850076079738585      0.000     0.000     0.000       1.0\n",
      "-2667904589560259752      0.000     0.000     0.000       0.0\n",
      "-2711021553879714602      0.000     0.000     0.000       0.0\n",
      "-2750066387561310925      0.000     0.000     0.000       0.0\n",
      "-2765509173420798202      0.000     0.000     0.000       1.0\n",
      "-2767732750007597807      0.000     0.000     0.000       1.0\n",
      " -280329620064517972      0.000     0.000     0.000       1.0\n",
      "-2820200531701074429      0.000     0.000     0.000       1.0\n",
      "-2835750527133753315      0.000     0.000     0.000       1.0\n",
      "-2854462519984664369      0.000     0.000     0.000       1.0\n",
      "-2889308232100140417      0.000     0.000     0.000       0.0\n",
      "-2903143988503755110      0.000     0.000     0.000       0.0\n",
      "-2957453829952515970      0.000     0.000     0.000       1.0\n",
      "-2976595678277848147      0.000     0.000     0.000       1.0\n",
      "-2982860695636507819      0.000     0.000     0.000       0.0\n",
      " -301265274697029653      0.000     0.000     0.000       0.0\n",
      "-3063703895887814987      0.000     0.000     0.000       1.0\n",
      "-3147733087665629263      0.000     0.000     0.000       0.0\n",
      "-3155613315185854456      0.000     0.000     0.000       1.0\n",
      "-3184581495316830885      0.000     0.000     0.000       0.0\n",
      "-3240307929837486686      0.000     0.000     0.000       0.0\n",
      " -328721490944343347      0.000     0.000     0.000       1.0\n",
      "-3290149407391132246      0.000     0.000     0.000       0.0\n",
      "-3292174228153670291      0.000     0.000     0.000       1.0\n",
      "-3323671968624279647      0.000     0.000     0.000       1.0\n",
      " -336458739649806874      0.000     0.000     0.000       0.0\n",
      "-3427206172862159409      0.000     0.000     0.000       1.0\n",
      "-3441471956267812417      0.000     0.000     0.000       1.0\n",
      " -346292032955285116      0.000     0.000     0.000       1.0\n",
      "-3476485156155395030      0.000     0.000     0.000       0.0\n",
      "-3514610216589353424      0.000     0.000     0.000       1.0\n",
      "-3535284628618578775      0.000     0.000     0.000       1.0\n",
      "-3558458043847582526      0.000     0.000     0.000       1.0\n",
      "-3578146495450837315      0.000     0.000     0.000       0.0\n",
      "-3581941614347715304      0.000     0.000     0.000       1.0\n",
      "-3612488709922774850      0.000     0.000     0.000       1.0\n",
      "-3662569876908007344      0.000     0.000     0.000       1.0\n",
      "  -36628014610122863      0.000     0.000     0.000       0.0\n",
      "-3698572405993660441      0.000     0.000     0.000       0.0\n",
      "-3704784093861151955      0.000     0.000     0.000       0.0\n",
      "-3711740572405425297      0.000     0.000     0.000       0.0\n",
      "-3756019310465605087      0.000     0.000     0.000       1.0\n",
      "-3784572097591019281      0.000     0.000     0.000       0.0\n",
      "-3805864280017366149      0.000     0.000     0.000       0.0\n",
      "-3827845872840027857      0.000     0.000     0.000       0.0\n",
      "-3829163328073056190      0.000     0.000     0.000       1.0\n",
      "-3857526458668256689      0.000     0.000     0.000       2.0\n",
      "-3871175249703859900      0.000     0.000     0.000       0.0\n",
      "-3875223927138611773      0.000     0.000     0.000       1.0\n",
      "-3899907778559379303      0.000     0.000     0.000       1.0\n",
      "-3900029853181998660      0.000     0.000     0.000       0.0\n",
      "-3911985325560349930      0.000     0.000     0.000       1.0\n",
      "-3913168020767254625      0.000     0.000     0.000       0.0\n",
      "-3995452403140212707      0.000     0.000     0.000       1.0\n",
      "-4033149501431418946      0.000     0.000     0.000       1.0\n",
      "-4052648152686263285      0.000     0.000     0.000       0.0\n",
      "-4058951104140523671      0.000     0.000     0.000       1.0\n",
      "-4101633621618986535      0.000     0.000     0.000       1.0\n",
      "-4112174727507542639      0.000     0.000     0.000       1.0\n",
      "-4119077611783846164      0.000     0.000     0.000       0.0\n",
      "-4119400360659006638      0.000     0.000     0.000       1.0\n",
      "-4122111366769247643      0.000     0.000     0.000       1.0\n",
      "-4129206191376440561      0.000     0.000     0.000       0.0\n",
      "-4159782676957523050      0.000     0.000     0.000       1.0\n",
      " -416415521181781106      0.000     0.000     0.000       1.0\n",
      "-4185159772258955312      0.000     0.000     0.000       1.0\n",
      "-4204705340831974299      0.000     0.000     0.000       0.0\n",
      "-4233301350296564466      0.000     0.000     0.000       0.0\n",
      "-4253210795010992393      0.000     0.000     0.000       1.0\n",
      "-4257786054562229234      0.000     0.000     0.000       2.0\n",
      "-4274214306497854212      0.000     0.000     0.000       1.0\n",
      "-4334324126352373008      0.000     0.000     0.000       0.0\n",
      "-4347170900797926406      0.000     0.000     0.000       1.0\n",
      "  -43579219363067494      0.000     0.000     0.000       1.0\n",
      "-4409934705136703756      0.000     0.000     0.000       1.0\n",
      "-4456840635365631288      0.000     0.000     0.000       1.0\n",
      "-4503555714936092627      0.000     0.000     0.000       0.0\n",
      "-4508386013578743505      0.000     0.000     0.000       1.0\n",
      "-4533741777978322805      0.000     0.000     0.000       1.0\n",
      "-4566550047027796798      0.000     0.000     0.000       0.0\n",
      " -457159583267129289      0.000     0.000     0.000       0.0\n",
      "-4592154704237500643      0.000     0.000     0.000       0.0\n",
      " -459793114294540643      0.000     0.000     0.000       1.0\n",
      "-4614990665736335762      0.000     0.000     0.000       1.0\n",
      "-4622789592689440680      0.000     0.000     0.000       0.0\n",
      "-4632555270762566609      0.000     0.000     0.000       1.0\n",
      "-4714796398714423781      0.000     0.000     0.000       0.0\n",
      "-4721976236092111964      0.000     0.000     0.000       1.0\n",
      "-4738264777106933692      0.000     0.000     0.000       0.0\n",
      "-4838031017542095306      0.000     0.000     0.000       1.0\n",
      "  -48506876888393587      0.000     0.000     0.000       0.0\n",
      "-4854839713512637789      0.000     0.000     0.000       1.0\n",
      "-4942861777414921381      0.000     0.000     0.000       0.0\n",
      "-4960416208644223171      0.000     0.000     0.000       1.0\n",
      "-4980969901807956939      0.000     0.000     0.000       1.0\n",
      "-4994476902657579779      0.000     0.000     0.000       0.0\n",
      "-5002740211430094207      0.000     0.000     0.000       1.0\n",
      "-5009132692663953057      0.000     0.000     0.000       0.0\n",
      "-5089977178309343696      0.000     0.000     0.000       1.0\n",
      "-5118880498450042021      0.000     0.000     0.000       2.0\n",
      "-5129792083521462361      0.000     0.000     0.000       0.0\n",
      "-5140920034857055282      0.000     0.000     0.000       1.0\n",
      " -519700304462286815      0.000     0.000     0.000       1.0\n",
      "-5202225354553554749      0.000     0.000     0.000       1.0\n",
      "-5242144699283262557      0.000     0.000     0.000       0.0\n",
      "-5253868965699796910      0.000     0.000     0.000       1.0\n",
      "-5291462420630419547      0.000     0.000     0.000       0.0\n",
      "-5314546236359181433      0.000     0.000     0.000       1.0\n",
      "-5364347045134876813      0.000     0.000     0.000       0.0\n",
      "-5411900691260629707      0.000     0.000     0.000       1.0\n",
      "-5501035507647410191      0.000     0.000     0.000       0.0\n",
      "-5504136873788319214      0.000     0.000     0.000       0.0\n",
      "-5518984574195342854      0.000     0.000     0.000       1.0\n",
      "-5539704658160313948      0.000     0.000     0.000       1.0\n",
      "-5547260004205338810      0.000     0.000     0.000       1.0\n",
      "-5553292280737332655      0.000     0.000     0.000       0.0\n",
      "-5574050618706362324      0.000     0.000     0.000       1.0\n",
      "-5617207760867969587      0.000     0.000     0.000       0.0\n",
      "-5637875898396905230      0.000     0.000     0.000       1.0\n",
      "-5647215615936397287      0.000     0.000     0.000       1.0\n",
      "-5655682012144478648      0.000     0.000     0.000       1.0\n",
      "-5806489757259285657      0.000     0.000     0.000       0.0\n",
      "-5831400746031934795      0.000     0.000     0.000       1.0\n",
      "-5842338246809505903      0.000     0.000     0.000       0.0\n",
      "-5884043104882878465      0.000     0.000     0.000       1.0\n",
      " -591436192877109675      0.000     0.000     0.000       1.0\n",
      "-5926315553964577942      0.000     0.000     0.000       1.0\n",
      "-5967946232377383260      0.000     0.000     0.000       1.0\n",
      "-6005348629038799474      0.000     0.000     0.000       1.0\n",
      " -605459592661444245      0.000     0.000     0.000       0.0\n",
      "-6091614603666164601      0.000     0.000     0.000       0.0\n",
      "-6142599601973147352      0.000     0.000     0.000       1.0\n",
      "-6169789240788652015      0.000     0.000     0.000       0.0\n",
      "-6185880151292928806      0.000     0.000     0.000       1.0\n",
      "-6222291721806290876      0.000     0.000     0.000       1.0\n",
      "-6225355167298762723      0.000     0.000     0.000       1.0\n",
      "-6251472693154907586      0.000     0.000     0.000       1.0\n",
      "-6262732091714628462      0.000     0.000     0.000       1.0\n",
      "-6276018131635887239      0.000     0.000     0.000       0.0\n",
      "-6314945370533703759      0.000     0.000     0.000       1.0\n",
      "-6331272927827225927      0.000     0.000     0.000       1.0\n",
      "-6350587789391314022      0.000     0.000     0.000       1.0\n",
      "-6357753251464928105      0.000     0.000     0.000       0.0\n",
      "-6361327566317923864      0.000     0.000     0.000       2.0\n",
      "-6410263700229806876      0.000     0.000     0.000       1.0\n",
      "-6421952034449999003      0.000     0.000     0.000       0.0\n",
      "-6425637835933658145      0.000     0.000     0.000       0.0\n",
      "-6433889826519665311      0.000     0.000     0.000       0.0\n",
      "-6459152149432492829      0.000     0.000     0.000       0.0\n",
      "-6470461620135920141      0.000     0.000     0.000       0.0\n",
      "-6487360117943320517      0.000     0.000     0.000       1.0\n",
      "-6495069218731421295      0.000     0.000     0.000       0.0\n",
      "-6555525215199655985      0.000     0.000     0.000       1.0\n",
      "-6637016085343391660      0.000     0.000     0.000       1.0\n",
      "-6640007265063092819      0.000     0.000     0.000       0.0\n",
      "-6652336617353305278      0.000     0.000     0.000       1.0\n",
      "-6689802900622103386      0.000     0.000     0.000       1.0\n",
      "-6703588194228631064      0.000     0.000     0.000       0.0\n",
      "-6761563949367659705      0.000     0.000     0.000       1.0\n",
      "-6783248440165616353      0.000     0.000     0.000       0.0\n",
      " -679265706296691605      0.000     0.000     0.000       0.0\n",
      "-6799844350565294703      0.000     0.000     0.000       0.0\n",
      "-6818456305232746697      0.000     0.000     0.000       0.0\n",
      "-6834097676939789721      0.000     0.000     0.000       2.0\n",
      "-6834900642528629462      0.000     0.000     0.000       1.0\n",
      "-6844750320966914885      0.000     0.000     0.000       1.0\n",
      "-6871660299229649655      0.000     0.000     0.000       0.0\n",
      " -690114515220627649      0.000     0.000     0.000       0.0\n",
      "-6901205618757454336      0.000     0.000     0.000       1.0\n",
      "-6908849015695831205      0.000     0.000     0.000       1.0\n",
      "-6930310796287171799      0.000     0.000     0.000       1.0\n",
      " -695197907918850655      0.000     0.000     0.000       1.0\n",
      "-6958033156264493787      0.000     0.000     0.000       2.0\n",
      "-7010776539766091163      0.000     0.000     0.000       0.0\n",
      "-7051583928927019226      0.000     0.000     0.000       0.0\n",
      " -706289868220016076      0.000     0.000     0.000       0.0\n",
      "-7098608124241428995      0.000     0.000     0.000       1.0\n",
      " -716871993460833507      0.000     0.000     0.000       1.0\n",
      "-7177317000487092973      0.000     0.000     0.000       1.0\n",
      "-7200764956341041941      0.000     0.000     0.000       0.0\n",
      "-7211880577124155511      0.000     0.000     0.000       0.0\n",
      "-7304681912833825686      0.000     0.000     0.000       1.0\n",
      "-7351316151311331611      0.000     0.000     0.000       0.0\n",
      "-7422525289827895906      0.000     0.000     0.000       1.0\n",
      "-7452655144335113880      0.000     0.000     0.000       1.0\n",
      "-7454187512675277950      0.000     0.000     0.000       1.0\n",
      "-7605397393157955685      0.000     0.000     0.000       1.0\n",
      " -763336223263489268      0.000     0.000     0.000       1.0\n",
      "-7651412663314529955      0.000     0.000     0.000       1.0\n",
      "-7668283527733502480      0.000     0.000     0.000       1.0\n",
      "-7736818432458413005      0.000     0.000     0.000       1.0\n",
      " -776251905784575731      0.000     0.000     0.000       1.0\n",
      " -781057618310798476      0.000     0.000     0.000       0.0\n",
      "-7833769028784046012      0.000     0.000     0.000       0.0\n",
      "-7844051711561676885      0.000     0.000     0.000       0.0\n",
      "-7934481099723808395      0.000     0.000     0.000       0.0\n",
      "-7939355439295417137      0.000     0.000     0.000       0.0\n",
      "-7954778061703095583      0.000     0.000     0.000       0.0\n",
      "-7974490012996028556      0.000     0.000     0.000       1.0\n",
      "-8001993369439453289      0.000     0.000     0.000       0.0\n",
      " -800367819680233035      0.000     0.000     0.000       1.0\n",
      "-8061924950033258065      0.000     0.000     0.000       1.0\n",
      "-8062636134880740213      0.000     0.000     0.000       1.0\n",
      "-8066034133922089836      0.000     0.000     0.000       1.0\n",
      "-8066586583742895435      0.000     0.000     0.000       0.0\n",
      "-8140412113064617655      0.000     0.000     0.000       1.0\n",
      "-8185444496810969066      0.000     0.000     0.000       0.0\n",
      "-8193642075228360529      0.000     0.000     0.000       0.0\n",
      "-8217104777462574197      0.000     0.000     0.000       1.0\n",
      "-8252085205995767285      0.000     0.000     0.000       1.0\n",
      "-8256230332069629235      0.000     0.000     0.000       1.0\n",
      "-8300947017034128040      0.000     0.000     0.000       0.0\n",
      "-8306380223131382002      0.000     0.000     0.000       1.0\n",
      "-8315290148604067614      0.000     0.000     0.000       0.0\n",
      "-8330786800871929295      0.000     0.000     0.000       0.0\n",
      "-8348364462905928320      0.000     0.000     0.000       1.0\n",
      "-8373049857088995076      0.000     0.000     0.000       1.0\n",
      "-8433883620271798763      0.000     0.000     0.000       0.0\n",
      "-8446562296336871503      0.000     0.000     0.000       2.0\n",
      "-8465269359791754201      0.000     0.000     0.000       1.0\n",
      "-8509477177958398399      0.000     0.000     0.000       0.0\n",
      "  -85155030805938653      0.000     0.000     0.000       0.0\n",
      "-8531012679461100086      0.000     0.000     0.000       1.0\n",
      "-8536690844999753799      0.000     0.000     0.000       1.0\n",
      "-8557772771842860260      0.000     0.000     0.000       0.0\n",
      "-8617129728846558199      0.000     0.000     0.000       1.0\n",
      "-8617607706476254113      0.000     0.000     0.000       0.0\n",
      "-8667928877484089880      0.000     0.000     0.000       1.0\n",
      "-8811625881075275983      0.000     0.000     0.000       1.0\n",
      "-8816615494439396954      0.000     0.000     0.000       1.0\n",
      "-8861133236440189562      0.000     0.000     0.000       0.0\n",
      "-8884378447980204942      0.000     0.000     0.000       1.0\n",
      " -890484070833299653      0.000     0.000     0.000       0.0\n",
      "-8910125947184081193      0.000     0.000     0.000       1.0\n",
      "-9007313114949154887      0.000     0.000     0.000       1.0\n",
      "-9016591479256963851      0.000     0.000     0.000       1.0\n",
      "-9030119219663148410      0.000     0.000     0.000       1.0\n",
      "-9047833568162485643      0.000     0.000     0.000       1.0\n",
      "-9049123726854023390      0.000     0.000     0.000       1.0\n",
      "-9052312187779998979      0.000     0.000     0.000       1.0\n",
      "-9069364779646151649      0.000     0.000     0.000       1.0\n",
      "-9088292728582718265      0.000     0.000     0.000       1.0\n",
      " -911258061939702842      0.000     0.000     0.000       0.0\n",
      "-9128721557945089745      0.000     0.000     0.000       1.0\n",
      "-9150446855553544805      0.000     0.000     0.000       1.0\n",
      "-9154402391160096882      0.000     0.000     0.000       0.0\n",
      "-9159300950468468492      0.000     0.000     0.000       1.0\n",
      " -955549154801133582      0.000     0.000     0.000       0.0\n",
      " -979892479050316813      0.000     0.000     0.000       0.0\n",
      " -990560982375462934      0.000     0.000     0.000       1.0\n",
      " -999235980072145236      0.000     0.000     0.000       1.0\n",
      " 1000788809739029490      0.000     0.000     0.000       1.0\n",
      " 1006581676586616017      0.000     0.000     0.000       1.0\n",
      " 1049173964639368103      0.000     0.000     0.000       1.0\n",
      " 1071785725994902287      0.000     0.000     0.000       1.0\n",
      " 1076042213852287678      0.000     0.000     0.000       1.0\n",
      "  109477134805741581      0.000     0.000     0.000       0.0\n",
      " 1101350058092942705      0.000     0.000     0.000       1.0\n",
      " 1109452343723576345      0.000     0.000     0.000       0.0\n",
      " 1258323543585175174      0.000     0.000     0.000       1.0\n",
      " 1269840991190695128      0.000     0.000     0.000       1.0\n",
      " 1273444208233750146      0.000     0.000     0.000       0.0\n",
      " 1277339172449841034      0.000     0.000     0.000       0.0\n",
      " 1334616826938186636      0.000     0.000     0.000       1.0\n",
      " 1344231894009179759      0.000     0.000     0.000       0.0\n",
      " 1376064834581337564      0.000     0.000     0.000       1.0\n",
      " 1426598127480852839      0.000     0.000     0.000       0.0\n",
      " 1431485646311764615      0.000     0.000     0.000       0.0\n",
      "  147694807991649780      0.000     0.000     0.000       1.0\n",
      " 1487952607710973032      0.000     0.000     0.000       0.0\n",
      " 1509552258317823611      0.000     0.000     0.000       0.0\n",
      " 1613263298073961283      0.000     0.000     0.000       0.0\n",
      " 1642097723084207558      0.000     0.000     0.000       1.0\n",
      " 1725662455610580933      0.000     0.000     0.000       1.0\n",
      " 1729914880193300866      0.000     0.000     0.000       1.0\n",
      "  175700935925725975      0.000     0.000     0.000       1.0\n",
      " 1770757944632074405      0.000     0.000     0.000       0.0\n",
      " 1801621733363364886      0.000     0.000     0.000       1.0\n",
      " 1810268314503593173      0.000     0.000     0.000       1.0\n",
      " 1814146831188026177      0.000     0.000     0.000       1.0\n",
      " 1835106726124922588      0.000     0.000     0.000       0.0\n",
      " 1836023339329638089      0.000     0.000     0.000       1.0\n",
      "  185005102453208557      0.000     0.000     0.000       0.0\n",
      " 1878897874349298792      0.000     0.000     0.000       1.0\n",
      " 1913843489372061361      0.000     0.000     0.000       0.0\n",
      " 1928353941284224406      0.000     0.000     0.000       0.0\n",
      " 1939742608879207810      0.000     0.000     0.000       1.0\n",
      " 1945686900509745276      0.000     0.000     0.000       0.0\n",
      " 1952599116897054682      0.000     0.000     0.000       1.0\n",
      " 2014352967711468611      0.000     0.000     0.000       0.0\n",
      " 2037709400188962565      0.000     0.000     0.000       0.0\n",
      "  205293448139985668      0.000     0.000     0.000       1.0\n",
      " 2059712105263749933      0.000     0.000     0.000       0.0\n",
      "  206814595097005041      0.000     0.000     0.000       0.0\n",
      " 2133326342084386789      0.000     0.000     0.000       0.0\n",
      " 2174521838670258015      0.000     0.000     0.000       1.0\n",
      " 2175364583136554359      0.000     0.000     0.000       1.0\n",
      " 2182470580395818197      0.000     0.000     0.000       0.0\n",
      " 2231220761825221293      0.000     0.000     0.000       1.0\n",
      " 2239358061573923871      0.000     0.000     0.000       1.0\n",
      " 2256243836599683293      0.000     0.000     0.000       0.0\n",
      " 2317576905770714034      0.000     0.000     0.000       0.0\n",
      " 2344067684326568056      0.000     0.000     0.000       1.0\n",
      " 2346465756369591615      0.000     0.000     0.000       1.0\n",
      " 2348246203235256274      0.000     0.000     0.000       0.0\n",
      " 2367552652379433065      0.000     0.000     0.000       1.0\n",
      " 2375187503450309827      0.000     0.000     0.000       1.0\n",
      " 2435386711317151280      0.000     0.000     0.000       0.0\n",
      "  247585075639491724      0.000     0.000     0.000       0.0\n",
      " 2545666479118135865      0.000     0.000     0.000       0.0\n",
      " 2617993010525351899      0.000     0.000     0.000       0.0\n",
      " 2624379975727448148      0.000     0.000     0.000       0.0\n",
      " 2650428658024067679      0.000     0.000     0.000       1.0\n",
      " 2710028402311280415      0.000     0.000     0.000       0.0\n",
      "  275974864173845552      0.000     0.000     0.000       1.0\n",
      " 2781413849482647129      0.000     0.000     0.000       0.0\n",
      " 2789176811794026721      0.000     0.000     0.000       0.0\n",
      "  279661504937762514      0.000     0.000     0.000       0.0\n",
      " 2833692339217332935      0.000     0.000     0.000       0.0\n",
      " 2866198124478078641      0.000     0.000     0.000       1.0\n",
      " 3001637690119037133      0.000     0.000     0.000       0.0\n",
      " 3038934465434227329      0.000     0.000     0.000       1.0\n",
      " 3080179366198893636      0.000     0.000     0.000       1.0\n",
      " 3099543346810594121      0.000     0.000     0.000       1.0\n",
      " 3156102246711686721      0.000     0.000     0.000       1.0\n",
      " 3248921366887378778      0.000     0.000     0.000       0.0\n",
      " 3293055829085032957      0.000     0.000     0.000       1.0\n",
      " 3294939406840052377      0.000     0.000     0.000       1.0\n",
      " 3313025148240224654      0.000     0.000     0.000       0.0\n",
      " 3318811831253122337      0.000     0.000     0.000       0.0\n",
      " 3326430520138599398      0.000     0.000     0.000       1.0\n",
      " 3329801388521773306      0.000     0.000     0.000       1.0\n",
      " 3350104591880131003      0.000     0.000     0.000       0.0\n",
      " 3396614349057322614      0.000     0.000     0.000       0.0\n",
      " 3451248373516728135      0.000     0.000     0.000       1.0\n",
      " 3475378848799755274      0.000     0.000     0.000       0.0\n",
      " 3492017873516280991      0.000     0.000     0.000       0.0\n",
      " 3527568218738211321      0.000     0.000     0.000       1.0\n",
      " 3557563896152748589      0.000     0.000     0.000       0.0\n",
      " 3583568598459942257      0.000     0.000     0.000       1.0\n",
      "  360733328792456523      0.000     0.000     0.000       0.0\n",
      " 3617039878953204138      0.000     0.000     0.000       0.0\n",
      " 3703726385366861941      0.000     0.000     0.000       1.0\n",
      " 3716883081863282926      0.000     0.000     0.000       2.0\n",
      " 3719701241445800985      0.000     0.000     0.000       0.0\n",
      " 3790617303535945386      0.000     0.000     0.000       0.0\n",
      " 3804016767926625940      0.000     0.000     0.000       1.0\n",
      " 3829370932275896170      0.000     0.000     0.000       0.0\n",
      " 3896425090690721671      0.000     0.000     0.000       1.0\n",
      " 3916485571350472445      0.000     0.000     0.000       1.0\n",
      " 3954284917672582463      0.000     0.000     0.000       0.0\n",
      " 3971554669672838763      0.000     0.000     0.000       1.0\n",
      " 3993698901689813555      0.000     0.000     0.000       1.0\n",
      " 3996638649450667307      0.000     0.000     0.000       0.0\n",
      " 4020799137998090451      0.000     0.000     0.000       2.0\n",
      "  409585343681626337      0.000     0.000     0.000       1.0\n",
      " 4138167504942563665      0.000     0.000     0.000       1.0\n",
      " 4138777678782048157      0.000     0.000     0.000       0.0\n",
      " 4145177920379445410      0.000     0.000     0.000       0.0\n",
      " 4151927934630227683      0.000     0.000     0.000       2.0\n",
      " 4242009723814558601      0.000     0.000     0.000       1.0\n",
      " 4270866064861412701      0.000     0.000     0.000       1.0\n",
      " 4314778866663955769      0.000     0.000     0.000       1.0\n",
      " 4349589405280550694      0.000     0.000     0.000       1.0\n",
      " 4384501917807933111      0.000     0.000     0.000       2.0\n",
      " 4396231194866725998      0.000     0.000     0.000       1.0\n",
      " 4401772328763372195      0.000     0.000     0.000       2.0\n",
      " 4409066792884773127      0.000     0.000     0.000       1.0\n",
      " 4418475258248077446      0.000     0.000     0.000       1.0\n",
      " 4428911739309434789      0.000     0.000     0.000       0.0\n",
      " 4534126123324410760      0.000     0.000     0.000       0.0\n",
      "  455535267443786332      0.000     0.000     0.000       0.0\n",
      " 4579966482514605982      0.000     0.000     0.000       0.0\n",
      " 4586773996533306626      0.000     0.000     0.000       0.0\n",
      " 4602481477249583881      0.000     0.000     0.000       0.0\n",
      " 4610617576861686323      0.000     0.000     0.000       0.0\n",
      " 4625756354682202149      0.000     0.000     0.000       0.0\n",
      " 4633839120559719726      0.000     0.000     0.000       0.0\n",
      " 4670357492958964982      0.000     0.000     0.000       1.0\n",
      " 4705600182542456283      0.000     0.000     0.000       1.0\n",
      " 4764142976112690366      0.000     0.000     0.000       1.0\n",
      " 4767028639034602802      0.000     0.000     0.000       1.0\n",
      " 4785310044001633898      0.000     0.000     0.000       0.0\n",
      " 4804759830187954209      0.000     0.000     0.000       0.0\n",
      " 4833651301467451401      0.000     0.000     0.000       1.0\n",
      " 4850444047597440364      0.000     0.000     0.000       0.0\n",
      " 4897233384808429470      0.000     0.000     0.000       1.0\n",
      " 4923369925856272765      0.000     0.000     0.000       0.0\n",
      " 4924681254159050377      0.000     0.000     0.000       2.0\n",
      " 4976221114011193874      0.000     0.000     0.000       0.0\n",
      " 5060046896753012315      0.000     0.000     0.000       0.0\n",
      " 5071580552890348691      0.000     0.000     0.000       0.0\n",
      " 5072625015068965815      0.000     0.000     0.000       1.0\n",
      " 5095941974221034105      0.000     0.000     0.000       0.0\n",
      " 5118765321446767141      0.000     0.000     0.000       1.0\n",
      "  513160627914490573      0.000     0.000     0.000       1.0\n",
      " 5146587353750485111      0.000     0.000     0.000       0.0\n",
      " 5184557967624847848      0.000     0.000     0.000       0.0\n",
      " 5185961048071237755      0.000     0.000     0.000       1.0\n",
      " 5274876773343715808      0.000     0.000     0.000       0.0\n",
      " 5317234780830960759      0.000     0.000     0.000       0.0\n",
      " 5324662168423402623      0.000     0.000     0.000       0.0\n",
      " 5341277924471965165      0.000     0.000     0.000       0.0\n",
      " 5350082963367853055      0.000     0.000     0.000       0.0\n",
      " 5353864262418735314      0.000     0.000     0.000       0.0\n",
      " 5365750855855011689      0.000     0.000     0.000       1.0\n",
      " 5443459851731265365      0.000     0.000     0.000       1.0\n",
      " 5449712344589491615      0.000     0.000     0.000       1.0\n",
      " 5454562798244757391      0.000     0.000     0.000       1.0\n",
      " 5466262094720456105      0.000     0.000     0.000       0.0\n",
      " 5487704876705509466      0.000     0.000     0.000       0.0\n",
      "  550075796267367235      0.000     0.000     0.000       0.0\n",
      " 5507307987434090637      0.000     0.000     0.000       0.0\n",
      " 5517285735624852127      0.000     0.000     0.000       0.0\n",
      " 5597146025970746260      0.000     0.000     0.000       1.0\n",
      " 5602643818934195660      0.000     0.000     0.000       1.0\n",
      " 5609721013688775959      0.000     0.000     0.000       1.0\n",
      " 5712910853919608057      0.000     0.000     0.000       0.0\n",
      " 5718413951099404746      0.000     0.000     0.000       1.0\n",
      " 5723433304395011379      0.000     0.000     0.000       1.0\n",
      "  572437495102515516      0.000     0.000     0.000       0.0\n",
      " 5756521239679239940      0.000     0.000     0.000       0.0\n",
      " 5797221512815943098      0.000     0.000     0.000       1.0\n",
      " 5807949508958213307      0.000     0.000     0.000       0.0\n",
      " 5866120045143781178      0.000     0.000     0.000       1.0\n",
      " 5871436413576028875      0.000     0.000     0.000       0.0\n",
      " 5899440952510287121      0.000     0.000     0.000       1.0\n",
      " 5906822705980303334      0.000     0.000     0.000       0.0\n",
      " 5925140906298453426      0.000     0.000     0.000       0.0\n",
      " 5969096885696166402      0.000     0.000     0.000       1.0\n",
      " 6003195450477688924      0.000     0.000     0.000       0.0\n",
      " 6046610991727971517      0.000     0.000     0.000       1.0\n",
      " 6086587058091413791      0.000     0.000     0.000       0.0\n",
      " 6137221179599140574      0.000     0.000     0.000       1.0\n",
      " 6151494182082728507      0.000     0.000     0.000       1.0\n",
      " 6155927713441901365      0.000     0.000     0.000       1.0\n",
      " 6238782958132708071      0.000     0.000     0.000       1.0\n",
      " 6272129376266380255      0.000     0.000     0.000       0.0\n",
      "  643562760587028951      0.000     0.000     0.000       1.0\n",
      " 6455716303465707992      0.000     0.000     0.000       0.0\n",
      " 6564894856056328079      0.000     0.000     0.000       0.0\n",
      " 6567518670562087751      0.000     0.000     0.000       1.0\n",
      " 6604266875071040931      0.000     0.000     0.000       0.0\n",
      " 6658047495981975986      0.000     0.000     0.000       0.0\n",
      " 6696553251254932475      0.000     0.000     0.000       1.0\n",
      " 6714768841688746514      0.000     0.000     0.000       0.0\n",
      " 6727234431122028633      0.000     0.000     0.000       1.0\n",
      " 6749619878942220528      0.000     0.000     0.000       1.0\n",
      " 6760976112593931917      0.000     0.000     0.000       1.0\n",
      " 6784963440957539959      0.000     0.000     0.000       0.0\n",
      " 6869419155092690736      0.000     0.000     0.000       1.0\n",
      " 6887397625991071210      0.000     0.000     0.000       1.0\n",
      " 6898681408887153823      0.000     0.000     0.000       1.0\n",
      " 6908317125015524420      0.000     0.000     0.000       0.0\n",
      "  692030470764423827      0.000     0.000     0.000       1.0\n",
      " 6928907027962492643      0.000     0.000     0.000       0.0\n",
      " 6948430001044129321      0.000     0.000     0.000       0.0\n",
      " 6973547765135568882      0.000     0.000     0.000       1.0\n",
      " 7040703912178460558      0.000     0.000     0.000       0.0\n",
      " 7061473993433278893      0.000     0.000     0.000       0.0\n",
      " 7076642500414540824      0.000     0.000     0.000       1.0\n",
      " 7084785533455382925      0.000     0.000     0.000       1.0\n",
      "  717064707413884756      0.000     0.000     0.000       1.0\n",
      " 7174725888580472417      0.000     0.000     0.000       1.0\n",
      " 7178129690008942038      0.000     0.000     0.000       1.0\n",
      " 7299909841760607725      0.000     0.000     0.000       1.0\n",
      " 7424334660572136687      0.000     0.000     0.000       0.0\n",
      "  742446751966389221      0.000     0.000     0.000       1.0\n",
      " 7434092720977567346      0.000     0.000     0.000       1.0\n",
      " 7439952275838077619      0.000     0.000     0.000       1.0\n",
      " 7460420936666594598      0.000     0.000     0.000       1.0\n",
      " 7486643864207729420      0.000     0.000     0.000       0.0\n",
      " 7488807284931846539      0.000     0.000     0.000       0.0\n",
      " 7495389258173757737      0.000     0.000     0.000       0.0\n",
      " 7511672750567408075      0.000     0.000     0.000       1.0\n",
      "  752581435251137071      0.000     0.000     0.000       0.0\n",
      " 7528332892319417201      0.000     0.000     0.000       1.0\n",
      " 7553001473398663052      0.000     0.000     0.000       1.0\n",
      "  756307608455612639      0.000     0.000     0.000       1.0\n",
      " 7593386286046462855      0.000     0.000     0.000       1.0\n",
      " 7595909029680080614      0.000     0.000     0.000       1.0\n",
      "  761588865561616682      0.000     0.000     0.000       0.0\n",
      " 7620508853456457791      0.000     0.000     0.000       1.0\n",
      " 7658251345732969690      0.000     0.000     0.000       0.0\n",
      " 7679089547005805957      0.000     0.000     0.000       0.0\n",
      " 7680153893248040121      0.000     0.000     0.000       0.0\n",
      "  769381184495775319      0.000     0.000     0.000       0.0\n",
      " 7716491216499182839      0.000     0.000     0.000       1.0\n",
      "  778250704108860720      0.000     0.000     0.000       1.0\n",
      " 7796389280256489001      0.000     0.000     0.000       1.0\n",
      "  780214947720007732      0.000     0.000     0.000       0.0\n",
      "  787850280359399814      0.000     0.000     0.000       0.0\n",
      " 7902843977894659416      0.000     0.000     0.000       1.0\n",
      " 7911285228700881061      0.000     0.000     0.000       1.0\n",
      "  796083194311103182      0.000     0.000     0.000       1.0\n",
      " 7963068243904773147      0.000     0.000     0.000       2.0\n",
      " 7987579648442089875      0.000     0.000     0.000       0.0\n",
      " 8000928811516913142      0.000     0.000     0.000       1.0\n",
      " 8009901408153854394      0.000     0.000     0.000       1.0\n",
      " 8015893081454066637      0.000     0.000     0.000       0.0\n",
      " 8020817944616956279      0.000     0.000     0.000       1.0\n",
      " 8021527975825923142      0.000     0.000     0.000       1.0\n",
      " 8022787081325698411      0.000     0.000     0.000       0.0\n",
      " 8026751988009804990      0.000     0.000     0.000       1.0\n",
      " 8050591731487231237      0.000     0.000     0.000       1.0\n",
      " 8061244628681871235      0.000     0.000     0.000       0.0\n",
      " 8091396337211856601      0.000     0.000     0.000       0.0\n",
      " 8095238552805913485      0.000     0.000     0.000       0.0\n",
      "  811292289315775301      0.000     0.000     0.000       0.0\n",
      " 8134388861537950352      0.000     0.000     0.000       1.0\n",
      " 8258355968149608952      0.000     0.000     0.000       1.0\n",
      " 8265247532816798556      0.000     0.000     0.000       1.0\n",
      " 8287026168525413008      0.000     0.000     0.000       1.0\n",
      " 8339460541406031249      0.000     0.000     0.000       1.0\n",
      " 8385997530446946911      0.000     0.000     0.000       1.0\n",
      " 8393135757933840881      0.000     0.000     0.000       0.0\n",
      " 8396171626312864197      0.000     0.000     0.000       0.0\n",
      " 8423817508619884982      0.000     0.000     0.000       1.0\n",
      " 8481868866197056335      0.000     0.000     0.000       1.0\n",
      " 8558050916003277050      0.000     0.000     0.000       1.0\n",
      "  856527401085642863      0.000     0.000     0.000       0.0\n",
      " 8594699940152919876      0.000     0.000     0.000       2.0\n",
      " 8638862146664760718      0.000     0.000     0.000       1.0\n",
      "   86646190284079413      0.000     0.000     0.000       0.0\n",
      " 8671698840806419293      0.000     0.000     0.000       0.0\n",
      " 8682833030915075674      0.000     0.000     0.000       1.0\n",
      " 8695217378915273609      0.000     0.000     0.000       1.0\n",
      " 8719275538005785856      0.000     0.000     0.000       1.0\n",
      " 8728057174540749318      0.000     0.000     0.000       0.0\n",
      " 8783477700896046774      0.000     0.000     0.000       0.0\n",
      " 8808656676319796564      0.000     0.000     0.000       1.0\n",
      "  883181450294166961      0.000     0.000     0.000       1.0\n",
      " 8856402440707996345      0.000     0.000     0.000       0.0\n",
      " 8923717321378811689      0.000     0.000     0.000       1.0\n",
      " 8961480525217861282      0.000     0.000     0.000       1.0\n",
      "   90007550450171813      0.000     0.000     0.000       0.0\n",
      " 9011714303824805522      0.000     0.000     0.000       0.0\n",
      " 9020485838258490778      0.000     0.000     0.000       1.0\n",
      " 9089301679618857325      0.000     0.000     0.000       0.0\n",
      " 9091523574736953039      0.000     0.000     0.000       1.0\n",
      " 9096990173965533395      0.000     0.000     0.000       0.0\n",
      " 9106053593712063192      0.000     0.000     0.000       0.0\n",
      " 9114743927095072743      0.000     0.000     0.000       0.0\n",
      " 9132424145696606801      0.000     0.000     0.000       0.0\n",
      " 9146366784811072575      0.000     0.000     0.000       1.0\n",
      " 9148123901509291665      0.000     0.000     0.000       0.0\n",
      " 9157108568902534119      0.000     0.000     0.000       0.0\n",
      " 9178350981878228662      0.000     0.000     0.000       0.0\n",
      " 9179060066454762192      0.000     0.000     0.000       1.0\n",
      " 9183613611678617790      0.000     0.000     0.000       1.0\n",
      " 9202480423276128048      0.000     0.000     0.000       0.0\n",
      " 9219596265267399323      0.000     0.000     0.000       1.0\n",
      "   94241493540186362      0.000     0.000     0.000       0.0\n",
      "  958915585250403195      0.000     0.000     0.000       1.0\n",
      "\n",
      "            accuracy                          0.000     370.0\n",
      "           macro avg      0.000     0.000     0.000     370.0\n",
      "        weighted avg      0.000     0.000     0.000     370.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrics = evaluate(y_true, y_pred)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
